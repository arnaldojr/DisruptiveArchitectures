{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arnaldojr/DisruptiveArchitectures/blob/master/material/aulas/IA/lab08/cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "345d3fd2",
      "metadata": {},
      "source": [
        "# LaboratÃ³rio: Redes Neurais Convolucionais (CNNs) - Do BÃ¡sico ao AvanÃ§ado\n",
        "\n",
        "## ğŸ¯ Objetivos de Aprendizagem\n",
        "\n",
        "Ao final desta aula, vocÃª serÃ¡ capaz de:\n",
        "\n",
        "1. **Compreender** os fundamentos matemÃ¡ticos das CNNs\n",
        "2. **Implementar** redes convolucionais do zero usando TensorFlow/Keras\n",
        "3. **Aplicar** tÃ©cnicas avanÃ§adas como data augmentation e transfer learning\n",
        "4. **Comparar** CNNs com MLPs tradicionais\n",
        "5. **Resolver** problemas reais de visÃ£o computacional\n",
        "6. **Otimizar** modelos para diferentes cenÃ¡rios\n",
        "\n",
        "## ğŸ“š Material de Apoio ObrigatÃ³rio\n",
        "\n",
        "ğŸ“– **Leitura complementar**: [cnn_guia_completo.md](./cnn_guia_completo.md) - Guia teÃ³rico completo sobre CNNs\n",
        "\n",
        "## ğŸ§  Por que CNNs sÃ£o RevolucionÃ¡rias?\n",
        "\n",
        "### ğŸ’¡ Problema com MLPs Tradicionais\n",
        "\n",
        "Imagine processar uma imagem **400Ã—600 pixels** com um MLP:\n",
        "- **ParÃ¢metros**: 400 Ã— 600 Ã— 100 + 100 = **24.000.100** parÃ¢metros sÃ³ na primeira camada!\n",
        "- **Problemas**: \n",
        "  - ğŸš« Ignora estrutura espacial\n",
        "  - ğŸš« SensÃ­vel Ã  posiÃ§Ã£o\n",
        "  - ğŸš« Computacionalmente caro\n",
        "  - ğŸš« Overfitting garantido\n",
        "\n",
        "### âœ¨ SoluÃ§Ã£o das CNNs\n",
        "\n",
        "- âœ… **Compartilhamento de pesos**: Mesmos filtros em toda imagem\n",
        "- âœ… **InvariÃ¢ncia espacial**: Reconhece padrÃµes independente da posiÃ§Ã£o  \n",
        "- âœ… **Hierarquia de features**: Bordas â†’ Formas â†’ Objetos\n",
        "- âœ… **EficiÃªncia**: Drasticamente menos parÃ¢metros\n",
        "\n",
        "### ğŸ”¬ InspiraÃ§Ã£o BiolÃ³gica\n",
        "\n",
        "As CNNs sÃ£o inspiradas no **cÃ³rtex visual** dos mamÃ­feros:\n",
        "\n",
        "```\n",
        "CÃ©lulas simples â†’ CÃ©lulas complexas â†’ Ãrea V1 â†’ V2 â†’ V4 â†’ IT\n",
        "      â†“              â†“              â†“    â†“    â†“    â†“\n",
        "   Bordas         Formas       Texturas â†’ Partes â†’ Objetos\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f98ac337",
      "metadata": {
        "id": "f98ac337"
      },
      "source": [
        "## ğŸ”§ ConfiguraÃ§Ã£o do Ambiente\n",
        "\n",
        "Vamos comeÃ§ar importando todas as bibliotecas necessÃ¡rias e configurando o ambiente de desenvolvimento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbe5bb14",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ImportaÃ§Ãµes essenciais\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, optimizers, callbacks\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ConfiguraÃ§Ãµes para reprodutibilidade\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# ConfiguraÃ§Ãµes de visualizaÃ§Ã£o\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "\n",
        "# Verificar GPU disponÃ­vel\n",
        "print(\"ğŸ”§ CONFIGURAÃ‡ÃƒO DO AMBIENTE\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"TensorFlow versÃ£o: {tf.__version__}\")\n",
        "print(f\"Keras versÃ£o: {keras.__version__}\")\n",
        "print(f\"GPUs disponÃ­veis: {len(tf.config.list_physical_devices('GPU'))}\")\n",
        "\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    print(\"âœ… GPU detectada e configurada!\")\n",
        "    for gpu in tf.config.list_physical_devices('GPU'):\n",
        "        print(f\"   ğŸ“± {gpu}\")\n",
        "else:\n",
        "    print(\"âš ï¸ Executando em CPU - considere usar GPU para melhor performance\")\n",
        "\n",
        "print(\"\\nğŸš€ Ambiente configurado com sucesso!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad44177b",
      "metadata": {
        "id": "ad44177b"
      },
      "source": [
        "## ğŸ“Š Parte 1: CNN vs MLP - ComparaÃ§Ã£o PrÃ¡tica\n",
        "\n",
        "Vamos demonstrar **por que CNNs sÃ£o superiores** para dados de imagem atravÃ©s de uma comparaÃ§Ã£o direta.\n",
        "\n",
        "### ğŸ” AnÃ¡lise de ParÃ¢metros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6f015b9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# DemonstraÃ§Ã£o: MLP vs CNN - NÃºmero de ParÃ¢metros\n",
        "print(\"ğŸ”¢ COMPARAÃ‡ÃƒO: MLP vs CNN - NÃšMERO DE PARÃ‚METROS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Definindo dimensÃµes de uma imagem tÃ­pica\n",
        "altura, largura, canais = 400, 600, 3\n",
        "total_pixels = altura * largura * canais\n",
        "\n",
        "print(f\"ğŸ“ Imagem exemplo: {altura}Ã—{largura}Ã—{canais} = {total_pixels:,} pixels\")\n",
        "\n",
        "# MLP Tradicional\n",
        "print(f\"\\nğŸ§  MLP TRADICIONAL:\")\n",
        "print(f\"   Entrada: {total_pixels:,} pixels (flattened)\")\n",
        "print(f\"   Primeira camada: 100 neurÃ´nios\")\n",
        "parametros_mlp = total_pixels * 100 + 100  # pesos + bias\n",
        "print(f\"   ParÃ¢metros primeira camada: {parametros_mlp:,}\")\n",
        "print(f\"   ğŸ’¾ MemÃ³ria aproximada: {parametros_mlp * 4 / 1024**2:.2f} MB\")\n",
        "\n",
        "# CNN Equivalente\n",
        "print(f\"\\nğŸ” CNN EQUIVALENTE:\")\n",
        "print(f\"   Entrada: {altura}Ã—{largura}Ã—{canais}\")\n",
        "print(f\"   Conv2D: 32 filtros 3Ã—3\")\n",
        "parametros_cnn = (3 * 3 * canais * 32) + 32  # kernel_size Ã— input_channels Ã— filters + bias\n",
        "print(f\"   ParÃ¢metros primeira camada: {parametros_cnn:,}\")\n",
        "print(f\"   ğŸ’¾ MemÃ³ria aproximada: {parametros_cnn * 4 / 1024**2:.4f} MB\")\n",
        "\n",
        "print(f\"\\nğŸ“Š COMPARAÃ‡ÃƒO:\")\n",
        "reducao = parametros_mlp / parametros_cnn\n",
        "print(f\"   ğŸ”» ReduÃ§Ã£o de parÃ¢metros: {reducao:.0f}x\")\n",
        "print(f\"   ğŸ’° Economia de memÃ³ria: {(1 - parametros_cnn/parametros_mlp)*100:.1f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1797784",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando os modelos para comparaÃ§Ã£o visual\n",
        "print(\"ğŸ—ï¸ CONSTRUINDO MODELOS PARA COMPARAÃ‡ÃƒO\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Modelo MLP (simplificado para demonstraÃ§Ã£o)\n",
        "mlp_model = keras.Sequential([\n",
        "    layers.Flatten(input_shape=(28, 28, 1)),  # MNIST para exemplo prÃ¡tico\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "], name=\"MLP_Model\")\n",
        "\n",
        "# Modelo CNN equivalente\n",
        "cnn_model = keras.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "], name=\"CNN_Model\")\n",
        "\n",
        "print(\"ğŸ“‹ RESUMO DOS MODELOS:\")\n",
        "print(\"\\nğŸ§  MLP Model:\")\n",
        "mlp_model.summary()\n",
        "\n",
        "print(\"\\nğŸ” CNN Model:\")\n",
        "cnn_model.summary()\n",
        "\n",
        "# ComparaÃ§Ã£o de parÃ¢metros\n",
        "mlp_params = mlp_model.count_params()\n",
        "cnn_params = cnn_model.count_params()\n",
        "\n",
        "print(f\"\\nğŸ“Š COMPARAÃ‡ÃƒO FINAL:\")\n",
        "print(f\"   MLP parÃ¢metros: {mlp_params:,}\")\n",
        "print(f\"   CNN parÃ¢metros: {cnn_params:,}\")\n",
        "print(f\"   CNN Ã© {mlp_params/cnn_params:.1f}x mais eficiente!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe453c62",
      "metadata": {},
      "source": [
        "### ğŸ¨ Visualizando a DiferenÃ§a Estrutural\n",
        "\n",
        "<img src=\"https://github.com/arnaldojr/DisruptiveArchitectures/blob/master/material/aulas/lab08/flatten.png?raw=1\" width=\"600px\">\n",
        "\n",
        "**Problemas do MLP para Imagens:**\n",
        "- ğŸš« **Perda de estrutura espacial**: Pixels sÃ£o tratados independentemente\n",
        "- ğŸš« **InvariÃ¢ncia limitada**: SensÃ­vel Ã  posiÃ§Ã£o dos objetos\n",
        "- ğŸš« **ExplosÃ£o de parÃ¢metros**: Cresce exponencialmente com o tamanho da imagem\n",
        "- ğŸš« **Overfitting**: Muitos parÃ¢metros para poucos dados\n",
        "\n",
        "**Vantagens da CNN:**\n",
        "- âœ… **Preserva estrutura espacial**: ConvoluÃ§Ãµes mantÃªm relaÃ§Ãµes espaciais\n",
        "- âœ… **Compartilhamento de pesos**: Mesmo filtro detecta padrÃ£o em qualquer posiÃ§Ã£o\n",
        "- âœ… **Hierarquia de features**: Aprende caracterÃ­sticas progressivamente\n",
        "- âœ… **EficiÃªncia computacional**: Muito menos parÃ¢metros"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99b7156a",
      "metadata": {},
      "source": [
        "## ğŸ”¬ Parte 2: OperaÃ§Ã£o de ConvoluÃ§Ã£o - O CoraÃ§Ã£o das CNNs\n",
        "\n",
        "### ğŸ§® Fundamentos MatemÃ¡ticos\n",
        "\n",
        "A **convoluÃ§Ã£o** Ã© uma operaÃ§Ã£o matemÃ¡tica fundamental que permite **filtragem no domÃ­nio espacial**. Ã‰ aplicada atravÃ©s de **filtros/kernels** que \"varrem\" a imagem para detectar padrÃµes especÃ­ficos.\n",
        "\n",
        "#### ğŸ“ FÃ³rmula da ConvoluÃ§Ã£o 2D:\n",
        "```\n",
        "S(i,j) = (I * K)(i,j) = Î£Î£ I(i+m, j+n) Ã— K(m,n)\n",
        "                        m n\n",
        "```\n",
        "\n",
        "Onde:\n",
        "- `I`: Imagem de entrada\n",
        "- `K`: Kernel/filtro  \n",
        "- `S`: Feature map (resultado)\n",
        "\n",
        "### ğŸ¯ Como Funciona a ConvoluÃ§Ã£o\n",
        "\n",
        "#### 1ï¸âƒ£ **Kernel percorre a imagem**\n",
        "<img src=\"https://github.com/arnaldojr/DisruptiveArchitectures/blob/master/material/aulas/lab08/same_padding_no_strides.gif?raw=1\" width=\"400px\">\n",
        "\n",
        "*O kernel (cinza) varre a imagem (azul) produzindo o feature map (verde)*\n",
        "\n",
        "#### 2ï¸âƒ£ **OperaÃ§Ã£o em cada posiÃ§Ã£o**\n",
        "<img src=\"https://github.com/arnaldojr/DisruptiveArchitectures/blob/master/material/aulas/lab08/convolution.png?raw=1\" width=\"500px\">\n",
        "\n",
        "*Produto elemento a elemento + soma = valor do pixel no feature map*\n",
        "\n",
        "#### 3ï¸âƒ£ **Resultado para cada pixel**\n",
        "<img src=\"https://github.com/arnaldojr/DisruptiveArchitectures/blob/master/material/aulas/lab08/conv3d.gif?raw=1\" width=\"400px\">\n",
        "\n",
        "*VisualizaÃ§Ã£o 3D da operaÃ§Ã£o de convoluÃ§Ã£o*\n",
        "\n",
        "#### 4ï¸âƒ£ **Resultado final na imagem**\n",
        "<img src=\"https://github.com/arnaldojr/DisruptiveArchitectures/blob/master/material/aulas/lab08/convexp.png?raw=1\" width=\"600px\">\n",
        "\n",
        "*Diferentes kernels detectam diferentes caracterÃ­sticas*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cde19410",
      "metadata": {},
      "outputs": [],
      "source": [
        "# DemonstraÃ§Ã£o prÃ¡tica da operaÃ§Ã£o de convoluÃ§Ã£o\n",
        "print(\"ğŸ”¬ DEMONSTRAÃ‡ÃƒO PRÃTICA: OPERAÃ‡ÃƒO DE CONVOLUÃ‡ÃƒO\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Criando uma imagem simples para demonstraÃ§Ã£o\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Imagem 5x5 simples\n",
        "imagem = np.array([\n",
        "    [1, 2, 3, 0, 1],\n",
        "    [0, 1, 2, 3, 1], \n",
        "    [1, 0, 1, 2, 0],\n",
        "    [2, 1, 0, 1, 2],\n",
        "    [1, 0, 2, 1, 0]\n",
        "])\n",
        "\n",
        "# Kernel detector de borda vertical\n",
        "kernel_vertical = np.array([\n",
        "    [-1, 0, 1],\n",
        "    [-1, 0, 1],\n",
        "    [-1, 0, 1]\n",
        "])\n",
        "\n",
        "# Kernel detector de borda horizontal  \n",
        "kernel_horizontal = np.array([\n",
        "    [-1, -1, -1],\n",
        "    [ 0,  0,  0],\n",
        "    [ 1,  1,  1]\n",
        "])\n",
        "\n",
        "# Kernel detector de borda (Laplaciano)\n",
        "kernel_borda = np.array([\n",
        "    [-1, -1, -1],\n",
        "    [-1,  8, -1],\n",
        "    [-1, -1, -1]\n",
        "])\n",
        "\n",
        "def aplicar_convolucao_manual(imagem, kernel):\n",
        "    \"\"\"Aplica convoluÃ§Ã£o manualmente para demonstraÃ§Ã£o\"\"\"\n",
        "    img_h, img_w = imagem.shape\n",
        "    kernel_h, kernel_w = kernel.shape\n",
        "    \n",
        "    # Tamanho da saÃ­da\n",
        "    out_h = img_h - kernel_h + 1\n",
        "    out_w = img_w - kernel_w + 1\n",
        "    \n",
        "    resultado = np.zeros((out_h, out_w))\n",
        "    \n",
        "    for i in range(out_h):\n",
        "        for j in range(out_w):\n",
        "            # RegiÃ£o da imagem\n",
        "            regiao = imagem[i:i+kernel_h, j:j+kernel_w]\n",
        "            # Produto elemento a elemento + soma\n",
        "            resultado[i, j] = np.sum(regiao * kernel)\n",
        "    \n",
        "    return resultado\n",
        "\n",
        "# Aplicando diferentes kernels\n",
        "resultado_vertical = aplicar_convolucao_manual(imagem, kernel_vertical)\n",
        "resultado_horizontal = aplicar_convolucao_manual(imagem, kernel_horizontal)\n",
        "resultado_borda = aplicar_convolucao_manual(imagem, kernel_borda)\n",
        "\n",
        "# VisualizaÃ§Ã£o\n",
        "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
        "\n",
        "# Imagem original\n",
        "im1 = axes[0,0].imshow(imagem, cmap='gray')\n",
        "axes[0,0].set_title('ğŸ–¼ï¸ Imagem Original')\n",
        "axes[0,0].set_xticks([])\n",
        "axes[0,0].set_yticks([])\n",
        "\n",
        "# Kernels\n",
        "im2 = axes[0,1].imshow(kernel_vertical, cmap='RdBu')\n",
        "axes[0,1].set_title('ğŸ” Kernel Vertical')\n",
        "axes[0,1].set_xticks([])\n",
        "axes[0,1].set_yticks([])\n",
        "\n",
        "im3 = axes[0,2].imshow(kernel_horizontal, cmap='RdBu')\n",
        "axes[0,2].set_title('ğŸ” Kernel Horizontal')\n",
        "axes[0,2].set_xticks([])\n",
        "axes[0,2].set_yticks([])\n",
        "\n",
        "im4 = axes[0,3].imshow(kernel_borda, cmap='RdBu')\n",
        "axes[0,3].set_title('ğŸ” Kernel Borda')\n",
        "axes[0,3].set_xticks([])\n",
        "axes[0,3].set_yticks([])\n",
        "\n",
        "# Resultados\n",
        "axes[1,0].text(0.5, 0.5, 'Resultados â†’', ha='center', va='center', \n",
        "               transform=axes[1,0].transAxes, fontsize=12, fontweight='bold')\n",
        "axes[1,0].set_xticks([])\n",
        "axes[1,0].set_yticks([])\n",
        "\n",
        "im5 = axes[1,1].imshow(resultado_vertical, cmap='RdBu')\n",
        "axes[1,1].set_title('ğŸ“Š Bordas Verticais')\n",
        "axes[1,1].set_xticks([])\n",
        "axes[1,1].set_yticks([])\n",
        "\n",
        "im6 = axes[1,2].imshow(resultado_horizontal, cmap='RdBu')\n",
        "axes[1,2].set_title('ğŸ“Š Bordas Horizontais') \n",
        "axes[1,2].set_xticks([])\n",
        "axes[1,2].set_yticks([])\n",
        "\n",
        "im7 = axes[1,3].imshow(resultado_borda, cmap='RdBu')\n",
        "axes[1,3].set_title('ğŸ“Š Todas as Bordas')\n",
        "axes[1,3].set_xticks([])\n",
        "axes[1,3].set_yticks([])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('ğŸ”¬ DemonstraÃ§Ã£o: Diferentes Kernels = Diferentes CaracterÃ­sticas', \n",
        "             fontsize=14, fontweight='bold', y=1.02)\n",
        "plt.show()\n",
        "\n",
        "print(\"âœ… Observe como cada kernel detecta caracterÃ­sticas diferentes!\")\n",
        "print(\"ğŸ“ Os valores nos feature maps indicam a 'forÃ§a' da caracterÃ­stica detectada\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6276477",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemplo detalhado: calculando um pixel manualmente\n",
        "print(\"ğŸ§® EXEMPLO DETALHADO: CALCULANDO UM PIXEL\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "print(\"ğŸ–¼ï¸ Imagem (regiÃ£o 3Ã—3):\")\n",
        "regiao = imagem[0:3, 0:3]\n",
        "print(regiao)\n",
        "\n",
        "print(\"\\nğŸ” Kernel (detector de borda):\")\n",
        "print(kernel_borda)\n",
        "\n",
        "print(\"\\nğŸ§® CÃ¡lculo passo a passo:\")\n",
        "print(\"Produto elemento a elemento:\")\n",
        "produto = regiao * kernel_borda\n",
        "print(produto)\n",
        "\n",
        "print(f\"\\nâ• Soma de todos os elementos: {np.sum(produto)}\")\n",
        "print(f\"ğŸ“Š Resultado para o pixel (0,0) do feature map: {np.sum(produto)}\")\n",
        "\n",
        "print(\"\\nğŸ’¡ InterpretaÃ§Ã£o:\")\n",
        "if np.sum(produto) > 0:\n",
        "    print(\"   âœ… Valor positivo â†’ Borda detectada!\")\n",
        "else:\n",
        "    print(\"   âŒ Valor baixo â†’ Sem borda significativa\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "409d0366",
      "metadata": {},
      "source": [
        "## ğŸ’» ImplementaÃ§Ã£o em CÃ³digo - TensorFlow/Keras\n",
        "\n",
        "### ğŸ”§ Camada Convolucional\n",
        "\n",
        "A implementaÃ§Ã£o de uma camada convolucional Ã© surpreendentemente simples:\n",
        "\n",
        "```python\n",
        "layers.Conv2D(filters=100, kernel_size=(3, 3), activation='relu', input_shape=(height, width, channels))\n",
        "```\n",
        "\n",
        "**ParÃ¢metros principais:**\n",
        "- ğŸ”¢ **filters**: NÃºmero de filtros (kernels) - define quantos feature maps sÃ£o gerados\n",
        "- ğŸ“ **kernel_size**: Tamanho do filtro - (3,3) Ã© mais comum\n",
        "- âš¡ **activation**: FunÃ§Ã£o de ativaÃ§Ã£o aplicada apÃ³s convoluÃ§Ã£o\n",
        "- ğŸ“Š **input_shape**: Formato da entrada (apenas na primeira camada)\n",
        "\n",
        "**ParÃ¢metros avanÃ§ados:**\n",
        "- ğŸ‘£ **strides**: Passo do filtro (default: (1,1))\n",
        "- ğŸ¯ **padding**: 'valid' (sem padding) ou 'same' (mantÃ©m dimensÃ£o)\n",
        "- ğŸ”„ **dilation_rate**: ConvoluÃ§Ãµes dilatadas para campo receptivo maior"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b98d0bcc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemplo prÃ¡tico: implementando camada convolucional\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "print(\"ğŸ’» IMPLEMENTAÃ‡ÃƒO: CAMADA CONVOLUCIONAL\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Criando uma camada convolucional simples\n",
        "model_conv = keras.Sequential([\n",
        "    layers.Conv2D(\n",
        "        filters=100, \n",
        "        kernel_size=(3, 3), \n",
        "        activation='relu', \n",
        "        input_shape=(800, 600, 3),\n",
        "        name=\"conv_layer_1\"\n",
        "    ),\n",
        "])\n",
        "\n",
        "print(\"ğŸ“‹ RESUMO DO MODELO:\")\n",
        "model_conv.summary()\n",
        "\n",
        "print(f\"\\nğŸ” ANÃLISE DA CAMADA:\")\n",
        "print(f\"   ğŸ“ Entrada: (800, 600, 3)\")\n",
        "print(f\"   ğŸ”¢ Filtros: 100\")\n",
        "print(f\"   ğŸ“ Kernel: 3Ã—3\")\n",
        "print(f\"   ğŸ“Š SaÃ­da: (798, 798, 100)\")  # 800-3+1 = 798\n",
        "print(f\"   ğŸ¯ ParÃ¢metros: {(3*3*3 + 1) * 100:,}\")  # (kernelÃ—channels + bias) Ã— filters\n",
        "\n",
        "# Calculando parÃ¢metros manualmente para verificaÃ§Ã£o\n",
        "kernel_params = 3 * 3 * 3  # kernel_size Ã— kernel_size Ã— input_channels\n",
        "bias_params = 1\n",
        "total_per_filter = kernel_params + bias_params\n",
        "total_params = total_per_filter * 100  # Ã— number of filters\n",
        "\n",
        "print(f\"\\nğŸ§® CÃLCULO DE PARÃ‚METROS:\")\n",
        "print(f\"   Por filtro: {kernel_params} (pesos) + {bias_params} (bias) = {total_per_filter}\")\n",
        "print(f\"   Total: {total_per_filter} Ã— {100} filtros = {total_params:,} parÃ¢metros\")\n",
        "\n",
        "print(\"\\nğŸ’¡ OBSERVAÃ‡Ã•ES:\")\n",
        "print(\"   âœ… Cada filtro aprende a detectar uma caracterÃ­stica especÃ­fica\")\n",
        "print(\"   âœ… Mais filtros = mais caracterÃ­sticas detectadas\")\n",
        "print(\"   âœ… Kernel 3Ã—3 Ã© o mais comum (bom balance eficiÃªncia/expressividade)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a693e5b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemplo com diferentes configuraÃ§Ãµes\n",
        "print(\"ğŸ›ï¸ EXPLORANDO DIFERENTES CONFIGURAÃ‡Ã•ES\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Testando diferentes configuraÃ§Ãµes\n",
        "configs = [\n",
        "    {\"filters\": 32, \"kernel_size\": (3,3), \"nome\": \"Config BÃ¡sica\"},\n",
        "    {\"filters\": 64, \"kernel_size\": (5,5), \"nome\": \"Kernel Maior\"},\n",
        "    {\"filters\": 128, \"kernel_size\": (1,1), \"nome\": \"Pointwise Conv\"},\n",
        "    {\"filters\": 32, \"kernel_size\": (3,3), \"strides\": (2,2), \"nome\": \"Stride 2\"},\n",
        "]\n",
        "\n",
        "for i, config in enumerate(configs):\n",
        "    print(f\"\\n{i+1}ï¸âƒ£ {config['nome']}:\")\n",
        "    \n",
        "    # Removendo 'nome' para criar a camada\n",
        "    layer_config = {k: v for k, v in config.items() if k != 'nome'}\n",
        "    \n",
        "    model_temp = keras.Sequential([\n",
        "        layers.Conv2D(**layer_config, input_shape=(64, 64, 3))\n",
        "    ])\n",
        "    \n",
        "    # AnÃ¡lise da configuraÃ§Ã£o\n",
        "    output_shape = model_temp.layers[0].output_shape[1:]  # Remove batch dimension\n",
        "    params = model_temp.count_params()\n",
        "    \n",
        "    print(f\"   ğŸ“Š SaÃ­da: {output_shape}\")\n",
        "    print(f\"   ğŸ”¢ ParÃ¢metros: {params:,}\")\n",
        "    \n",
        "    # InterpretaÃ§Ã£o\n",
        "    if 'strides' in config and config['strides'] == (2,2):\n",
        "        print(\"   ğŸ’¡ Stride 2 â†’ reduz dimensÃ£o pela metade\")\n",
        "    if config['kernel_size'] == (1,1):\n",
        "        print(\"   ğŸ’¡ Kernel 1Ã—1 â†’ combina canais sem considerar vizinhanÃ§a espacial\")\n",
        "    if config['kernel_size'] == (5,5):\n",
        "        print(\"   ğŸ’¡ Kernel 5Ã—5 â†’ campo receptivo maior, mais contexto\")\n",
        "\n",
        "print(f\"\\nğŸ“ˆ RESUMO:\")\n",
        "print(\"   â€¢ Mais filtros â†’ mais caracterÃ­sticas detectadas\")\n",
        "print(\"   â€¢ Kernel maior â†’ mais contexto, mais parÃ¢metros\")\n",
        "print(\"   â€¢ Stride > 1 â†’ reduÃ§Ã£o de dimensionalidade\")\n",
        "print(\"   â€¢ Kernel 1Ã—1 â†’ reduÃ§Ã£o/expansÃ£o de canais eficiente\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f39d7e9",
      "metadata": {},
      "source": [
        "## ğŸ¯ Desafio 1: AnÃ¡lise de ParÃ¢metros\n",
        "\n",
        "**Pergunta:** Compare a quantidade de `Total params` - em uma rede CNN esse valor Ã© menor ou maior comparado com uma rede MLP?\n",
        "\n",
        "### ğŸ’¡ Para Responder:\n",
        "1. **Observe** os modelos criados acima\n",
        "2. **Compare** CNN (100 filtros 3Ã—3) vs MLP (entrada flattened)\n",
        "3. **Analise** como o compartilhamento de pesos afeta o total\n",
        "4. **Considere** o que acontece com imagens maiores\n",
        "\n",
        "### ğŸ” Experimento Guiado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c628bca",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ¯ DESAFIO 1: EXPERIMENTO PRÃTICO\n",
        "print(\"ğŸ¯ DESAFIO 1: ANÃLISE COMPARATIVA DE PARÃ‚METROS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Vamos comparar sistematicamente\n",
        "tamanhos_imagem = [(28, 28), (64, 64), (128, 128), (224, 224)]\n",
        "\n",
        "print(\"ğŸ“Š COMPARAÃ‡ÃƒO SISTEMÃTICA: MLP vs CNN\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for altura, largura in tamanhos_imagem:\n",
        "    print(f\"\\nğŸ–¼ï¸ IMAGEM {altura}Ã—{largura}Ã—3:\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    # MLP Model\n",
        "    mlp_temp = keras.Sequential([\n",
        "        layers.Flatten(input_shape=(altura, largura, 3)),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    \n",
        "    # CNN Model  \n",
        "    cnn_temp = keras.Sequential([\n",
        "        layers.Conv2D(32, (3,3), activation='relu', input_shape=(altura, largura, 3)),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "        layers.Conv2D(64, (3,3), activation='relu'),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    \n",
        "    mlp_params = mlp_temp.count_params()\n",
        "    cnn_params = cnn_temp.count_params()\n",
        "    razao = mlp_params / cnn_params\n",
        "    \n",
        "    print(f\"   ğŸ§  MLP parÃ¢metros: {mlp_params:,}\")\n",
        "    print(f\"   ğŸ” CNN parÃ¢metros: {cnn_params:,}\")\n",
        "    print(f\"   ğŸ“ˆ RazÃ£o MLP/CNN: {razao:.1f}x\")\n",
        "    \n",
        "    if razao > 1:\n",
        "        print(f\"   âœ… CNN Ã© {razao:.1f}x mais eficiente!\")\n",
        "    else:\n",
        "        print(f\"   âš ï¸ MLP Ã© mais eficiente para esta configuraÃ§Ã£o\")\n",
        "\n",
        "print(f\"\\nğŸ¯ SUA ANÃLISE:\")\n",
        "print(\"=\" * 30)\n",
        "print(\"Com base nos resultados acima, complete:\")\n",
        "print(\"\\n1ï¸âƒ£ Em geral, CNNs tÃªm _______ parÃ¢metros que MLPs\")\n",
        "print(\"2ï¸âƒ£ Isso acontece porque CNNs usam _______\")\n",
        "print(\"3ï¸âƒ£ Quando a imagem fica maior, a diferenÃ§a _______\")\n",
        "print(\"4ï¸âƒ£ Para imagens pequenas, a vantagem da CNN _______\")\n",
        "\n",
        "print(f\"\\nğŸ’­ REFLEXÃƒO:\")\n",
        "print(\"Por que a CNN mantÃ©m vantagem mesmo com imagens grandes?\")\n",
        "print(\"Sua resposta: ________________________________\")\n",
        "\n",
        "# COMPLETE SUAS RESPOSTAS AQUI:\n",
        "print(f\"\\nğŸ“ SUAS RESPOSTAS:\")\n",
        "resposta_1 = \"______\"  # menor/maior\n",
        "resposta_2 = \"______\"  # compartilhamento de pesos/mais camadas/etc\n",
        "resposta_3 = \"______\"  # aumenta/diminui/mantÃ©m\n",
        "resposta_4 = \"______\"  # Ã© maior/Ã© menor/desaparece\n",
        "\n",
        "print(f\"1ï¸âƒ£ Em geral, CNNs tÃªm {resposta_1} parÃ¢metros que MLPs\")\n",
        "print(f\"2ï¸âƒ£ Isso acontece porque CNNs usam {resposta_2}\")\n",
        "print(f\"3ï¸âƒ£ Quando a imagem fica maior, a diferenÃ§a {resposta_3}\")\n",
        "print(f\"4ï¸âƒ£ Para imagens pequenas, a vantagem da CNN {resposta_4}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b35d6f5",
      "metadata": {},
      "source": [
        "## ğŸŠ Parte 3: Pooling - Reduzindo Dimensionalidade com InteligÃªncia\n",
        "\n",
        "### ğŸ¯ O que Ã© Pooling?\n",
        "\n",
        "O **pooling** Ã© uma operaÃ§Ã£o de **subsampling** que:\n",
        "- ğŸ“‰ **Reduz dimensionalidade** dos feature maps\n",
        "- ğŸ¯ **MantÃ©m caracterÃ­sticas importantes** \n",
        "- âš¡ **Diminui custo computacional**\n",
        "- ğŸ›¡ï¸ **Adiciona invariÃ¢ncia** a pequenas translaÃ§Ãµes\n",
        "- ğŸš« **Reduz overfitting** \n",
        "\n",
        "### ğŸ” Tipos de Pooling\n",
        "\n",
        "#### 1ï¸âƒ£ **Max Pooling** (Mais Comum)\n",
        "- **OperaÃ§Ã£o**: Seleciona o **valor mÃ¡ximo** na janela\n",
        "- **IntuiÃ§Ã£o**: Preserva as caracterÃ­sticas **mais ativas**\n",
        "- **Uso**: DetecÃ§Ã£o de bordas, texturas\n",
        "\n",
        "#### 2ï¸âƒ£ **Average Pooling**\n",
        "- **OperaÃ§Ã£o**: Calcula a **mÃ©dia** dos valores na janela\n",
        "- **IntuiÃ§Ã£o**: Suaviza e reduz ruÃ­do\n",
        "- **Uso**: Menos comum, algumas arquiteturas especÃ­ficas\n",
        "\n",
        "#### 3ï¸âƒ£ **Global Average Pooling**\n",
        "- **OperaÃ§Ã£o**: MÃ©dia de todo o feature map â†’ 1 valor\n",
        "- **Vantagem**: Substitui camadas Dense finais\n",
        "- **BenefÃ­cio**: Reduz drasticamente overfitting\n",
        "\n",
        "### ğŸ“ MatemÃ¡tica do Pooling\n",
        "\n",
        "**Max Pooling 2Ã—2:**\n",
        "```\n",
        "Entrada (4Ã—4):           SaÃ­da (2Ã—2):\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚1  3  2  4â”‚           â”‚max(1,3,0,1) max(2,4,1,2)â”‚\n",
        "â”‚0  1  1  2â”‚    â†’      â”‚    = 3         = 4     â”‚\n",
        "â”‚2  2  0  1â”‚           â”‚max(2,2,3,1) max(0,1,3,5)â”‚\n",
        "â”‚3  1  3  5â”‚           â”‚    = 3         = 5     â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "\n",
        "Resultado: [3, 4]\n",
        "           [3, 5]\n",
        "```\n",
        "\n",
        "### ğŸ–¼ï¸ VisualizaÃ§Ã£o do Pooling\n",
        "\n",
        "<img src=\"https://github.com/arnaldojr/DisruptiveArchitectures/blob/master/material/aulas/lab08/pooling.png?raw=1\" width=\"500px\">\n",
        "\n",
        "*O pooling 2Ã—2 reduz a dimensionalidade pela metade*\n",
        "\n",
        "### ğŸ“Š Resultado Visual\n",
        "\n",
        "<img src=\"https://github.com/arnaldojr/DisruptiveArchitectures/blob/master/material/aulas/lab08/poolingexp1.png?raw=1\" width=\"600px\">\n",
        "\n",
        "*ComparaÃ§Ã£o: imagem original vs apÃ³s max pooling*\n",
        "\n",
        "### âš¡ ParÃ¢metros do Pooling\n",
        "\n",
        "**CaracterÃ­sticas importantes:**\n",
        "- ğŸ”¢ **Zero parÃ¢metros**: NÃ£o hÃ¡ pesos para aprender\n",
        "- ğŸ›ï¸ **Pool size**: Tamanho da janela (geralmente 2Ã—2)\n",
        "- ğŸ‘£ **Stride**: Passo do deslocamento (geralmente = pool_size)\n",
        "- ğŸ“ **Padding**: Raramente usado em pooling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "010c5de9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# DemonstraÃ§Ã£o prÃ¡tica do pooling\n",
        "print(\"ğŸŠ DEMONSTRAÃ‡ÃƒO PRÃTICA: OPERAÃ‡Ã•ES DE POOLING\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Criando uma imagem exemplo para demonstraÃ§Ã£o\n",
        "np.random.seed(42)\n",
        "imagem_exemplo = np.random.randint(0, 10, (8, 8))\n",
        "\n",
        "print(\"ğŸ–¼ï¸ IMAGEM EXEMPLO (8Ã—8):\")\n",
        "print(imagem_exemplo)\n",
        "\n",
        "def max_pooling_manual(imagem, pool_size=2, stride=2):\n",
        "    \"\"\"ImplementaÃ§Ã£o manual do max pooling para demonstraÃ§Ã£o\"\"\"\n",
        "    h, w = imagem.shape\n",
        "    out_h = (h - pool_size) // stride + 1\n",
        "    out_w = (w - pool_size) // stride + 1\n",
        "    \n",
        "    resultado = np.zeros((out_h, out_w))\n",
        "    \n",
        "    for i in range(out_h):\n",
        "        for j in range(out_w):\n",
        "            h_start = i * stride\n",
        "            h_end = h_start + pool_size\n",
        "            w_start = j * stride  \n",
        "            w_end = w_start + pool_size\n",
        "            \n",
        "            # Max pooling\n",
        "            resultado[i, j] = np.max(imagem[h_start:h_end, w_start:w_end])\n",
        "    \n",
        "    return resultado\n",
        "\n",
        "def avg_pooling_manual(imagem, pool_size=2, stride=2):\n",
        "    \"\"\"ImplementaÃ§Ã£o manual do average pooling\"\"\"\n",
        "    h, w = imagem.shape\n",
        "    out_h = (h - pool_size) // stride + 1\n",
        "    out_w = (w - pool_size) // stride + 1\n",
        "    \n",
        "    resultado = np.zeros((out_h, out_w))\n",
        "    \n",
        "    for i in range(out_h):\n",
        "        for j in range(out_w):\n",
        "            h_start = i * stride\n",
        "            h_end = h_start + pool_size\n",
        "            w_start = j * stride\n",
        "            w_end = w_start + pool_size\n",
        "            \n",
        "            # Average pooling\n",
        "            resultado[i, j] = np.mean(imagem[h_start:h_end, w_start:w_end])\n",
        "    \n",
        "    return resultado\n",
        "\n",
        "# Aplicando diferentes tipos de pooling\n",
        "max_pool_result = max_pooling_manual(imagem_exemplo)\n",
        "avg_pool_result = avg_pooling_manual(imagem_exemplo)\n",
        "\n",
        "# VisualizaÃ§Ã£o\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# Imagem original\n",
        "im1 = axes[0].imshow(imagem_exemplo, cmap='viridis', interpolation='nearest')\n",
        "axes[0].set_title('ğŸ–¼ï¸ Imagem Original (8Ã—8)')\n",
        "axes[0].set_xticks(range(8))\n",
        "axes[0].set_yticks(range(8))\n",
        "plt.colorbar(im1, ax=axes[0])\n",
        "\n",
        "# Max pooling\n",
        "im2 = axes[1].imshow(max_pool_result, cmap='viridis', interpolation='nearest')\n",
        "axes[1].set_title('ğŸ”¥ Max Pooling (4Ã—4)')\n",
        "axes[1].set_xticks(range(4))\n",
        "axes[1].set_yticks(range(4))\n",
        "plt.colorbar(im2, ax=axes[1])\n",
        "\n",
        "# Average pooling\n",
        "im3 = axes[2].imshow(avg_pool_result, cmap='viridis', interpolation='nearest')\n",
        "axes[2].set_title('ğŸ“Š Average Pooling (4Ã—4)')\n",
        "axes[2].set_xticks(range(4))\n",
        "axes[2].set_yticks(range(4))\n",
        "plt.colorbar(im3, ax=axes[2])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nğŸ“ RESULTADOS:\")\n",
        "print(f\"   Original: {imagem_exemplo.shape}\")\n",
        "print(f\"   Max Pooling: {max_pool_result.shape}\")\n",
        "print(f\"   Average Pooling: {avg_pool_result.shape}\")\n",
        "print(f\"   ReduÃ§Ã£o: {imagem_exemplo.size // max_pool_result.size}x menos pixels\")\n",
        "\n",
        "print(f\"\\nğŸ” COMPARAÃ‡ÃƒO DE VALORES:\")\n",
        "print(\"Max Pooling resultado:\")\n",
        "print(max_pool_result.astype(int))\n",
        "print(\"\\nAverage Pooling resultado:\")\n",
        "print(np.round(avg_pool_result, 1))\n",
        "\n",
        "print(\"\\nğŸ’¡ OBSERVAÃ‡Ã•ES:\")\n",
        "print(\"   âœ… Max pooling preserva caracterÃ­sticas mais 'fortes'\")\n",
        "print(\"   âœ… Average pooling suaviza e reduz ruÃ­do\")\n",
        "print(\"   âœ… Ambos reduzem dimensionalidade sem parÃ¢metros treinÃ¡veis\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9c852a8",
      "metadata": {},
      "source": [
        "## ImplementaÃ§Ã£o em cÃ³digo\n",
        "\n",
        "Para implementar pooling em Keras Ã© muito simples:\n",
        "\n",
        "```python\n",
        "layers.MaxPool2D(pool_size=2, strides=2)\n",
        "```\n",
        "\n",
        "**ParÃ¢metros principais:**\n",
        "- ğŸ›ï¸ **pool_size**: Tamanho da janela de pooling (2Ã—2 Ã© padrÃ£o)\n",
        "- ğŸ‘£ **strides**: Passo do deslocamento (geralmente = pool_size)  \n",
        "- ğŸ¯ **padding**: 'valid' (padrÃ£o) ou 'same'\n",
        "\n",
        "**Outros tipos:**\n",
        "- `layers.AveragePooling2D()`: Average pooling\n",
        "- `layers.GlobalMaxPooling2D()`: Max pooling global\n",
        "- `layers.GlobalAveragePooling2D()`: Average pooling global"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1edf97e1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemplo completo: Conv2D + MaxPooling2D\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "print(\"ğŸ—ï¸ EXEMPLO: CONVOLUÃ‡ÃƒO + POOLING\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Conv2D(filters=100, kernel_size=(3, 3), activation='relu', \n",
        "                  input_shape=(800, 600, 3), name=\"conv2d_layer\"),\n",
        "    layers.MaxPool2D(pool_size=2, strides=2, name=\"maxpool_layer\")\n",
        "])\n",
        "\n",
        "print(\"ğŸ“‹ RESUMO DO MODELO:\")\n",
        "model.summary()\n",
        "\n",
        "print(\"\\nğŸ” ANÃLISE DAS TRANSFORMAÃ‡Ã•ES:\")\n",
        "print(\"   ğŸ“ Entrada: (800, 600, 3)\")\n",
        "print(\"   ğŸ”„ ApÃ³s Conv2D: (798, 798, 100)\")  # 800-3+1 = 798\n",
        "print(\"   ğŸŠ ApÃ³s MaxPool: (399, 399, 100)\")  # 798/2 = 399\n",
        "print(\"   ğŸ“‰ ReduÃ§Ã£o total: ~4x menos pixels\")\n",
        "\n",
        "print(\"\\nğŸ’¡ OBSERVAÃ‡Ã•ES IMPORTANTES:\")\n",
        "print(\"   âœ… Pooling NÃƒO adiciona parÃ¢metros\")\n",
        "print(\"   âœ… Reduz dimensionalidade espacial\") \n",
        "print(\"   âœ… MantÃ©m nÃºmero de canais\")\n",
        "print(\"   âœ… Diminui custo computacional\")\n",
        "\n",
        "# Comparando com e sem pooling\n",
        "print(\"\\nâš–ï¸ COMPARAÃ‡ÃƒO: COM vs SEM POOLING\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Sem pooling\n",
        "model_sem_pool = keras.Sequential([\n",
        "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(64,64,3)),\n",
        "    layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Com pooling  \n",
        "model_com_pool = keras.Sequential([\n",
        "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(64,64,3)),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "print(f\"Sem pooling: {model_sem_pool.count_params():,} parÃ¢metros\")\n",
        "print(f\"Com pooling: {model_com_pool.count_params():,} parÃ¢metros\")\n",
        "print(f\"DiferenÃ§a: {abs(model_sem_pool.count_params() - model_com_pool.count_params()):,} parÃ¢metros\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83635f02",
      "metadata": {},
      "source": [
        "## ğŸ¯ Desafio 2: AnÃ¡lise do Pooling\n",
        "\n",
        "**Perguntas:**\n",
        "1. Qual a dimensÃ£o da imagem antes e depois do pooling?\n",
        "2. A camada de pooling alterou o `total params`?\n",
        "3. Por que o pooling nÃ£o tem parÃ¢metros treinÃ¡veis?\n",
        "\n",
        "### ğŸ” AnÃ¡lise Guiada:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a3efd66",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ¯ DESAFIO 2: ANÃLISE DO POOLING\n",
        "print(\"ğŸ¯ DESAFIO 2: ANÃLISE DETALHADA DO POOLING\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Vamos analisar passo a passo\n",
        "model_analise = keras.Sequential([\n",
        "    layers.Conv2D(100, (3,3), activation='relu', input_shape=(800, 600, 3)),\n",
        "    layers.MaxPool2D(pool_size=2, strides=2)\n",
        "])\n",
        "\n",
        "print(\"ğŸ“Š ANÃLISE DAS DIMENSÃ•ES:\")\n",
        "print(\"=\" * 30)\n",
        "\n",
        "# Simulando o forward pass para ver as dimensÃµes\n",
        "import numpy as np\n",
        "input_shape = (1, 800, 600, 3)  # Batch size = 1\n",
        "dummy_input = np.random.random(input_shape)\n",
        "\n",
        "# Passando pela primeira camada (Conv2D)\n",
        "conv_output = model_analise.layers[0](dummy_input)\n",
        "print(f\"ğŸ”„ ApÃ³s ConvoluÃ§Ã£o: {conv_output.shape}\")\n",
        "print(f\"   Entrada: (800, 600, 3)\")\n",
        "print(f\"   SaÃ­da:   {conv_output.shape[1:]}\") \n",
        "\n",
        "# Passando pela segunda camada (MaxPool2D)  \n",
        "pool_output = model_analise.layers[1](conv_output)\n",
        "print(f\"\\nğŸŠ ApÃ³s Max Pooling: {pool_output.shape}\")\n",
        "print(f\"   Entrada: {conv_output.shape[1:]}\")\n",
        "print(f\"   SaÃ­da:   {pool_output.shape[1:]}\")\n",
        "\n",
        "# Calculando reduÃ§Ã£o\n",
        "altura_reducao = conv_output.shape[1] / pool_output.shape[1]\n",
        "largura_reducao = conv_output.shape[2] / pool_output.shape[2]\n",
        "total_pixels_antes = conv_output.shape[1] * conv_output.shape[2]\n",
        "total_pixels_depois = pool_output.shape[1] * pool_output.shape[2]\n",
        "reducao_total = total_pixels_antes / total_pixels_depois\n",
        "\n",
        "print(f\"\\nğŸ“ REDUÃ‡ÃƒO DE DIMENSÃ•ES:\")\n",
        "print(f\"   Altura: {altura_reducao:.1f}x menor\")  \n",
        "print(f\"   Largura: {largura_reducao:.1f}x menor\")\n",
        "print(f\"   Total de pixels: {reducao_total:.1f}x reduÃ§Ã£o\")\n",
        "\n",
        "print(f\"\\nğŸ”¢ ANÃLISE DE PARÃ‚METROS:\")\n",
        "print(\"=\" * 30)\n",
        "conv_params = model_analise.layers[0].count_params()\n",
        "pool_params = model_analise.layers[1].count_params()\n",
        "total_params = model_analise.count_params()\n",
        "\n",
        "print(f\"   Conv2D parÃ¢metros: {conv_params:,}\")\n",
        "print(f\"   MaxPool2D parÃ¢metros: {pool_params:,}\")\n",
        "print(f\"   Total parÃ¢metros: {total_params:,}\")\n",
        "\n",
        "print(f\"\\nğŸ¯ SUAS RESPOSTAS:\")\n",
        "print(\"=\" * 20)\n",
        "print(\"1ï¸âƒ£ DimensÃ£o antes do pooling: ________________\")\n",
        "print(\"2ï¸âƒ£ DimensÃ£o depois do pooling: _______________\")\n",
        "print(\"3ï¸âƒ£ Pooling alterou total params? _____________\")\n",
        "print(\"4ï¸âƒ£ Por que pooling nÃ£o tem parÃ¢metros? _______\")\n",
        "print(\"   _________________________________________\")\n",
        "\n",
        "print(f\"\\nğŸ’¡ DICAS PARA RESPONDER:\")\n",
        "print(\"   â€¢ Observe os valores impressos acima\")\n",
        "print(\"   â€¢ Lembre-se: pooling Ã© uma operaÃ§Ã£o fixa (max ou mÃ©dia)\")\n",
        "print(\"   â€¢ Compare com a convoluÃ§Ã£o que TEM parÃ¢metros\")\n",
        "print(\"   â€¢ Pense na diferenÃ§a entre 'operaÃ§Ã£o' e 'aprendizado'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0eaf3f14",
      "metadata": {},
      "source": [
        "## ğŸ” Parte 4: Arquitetura Completa da CNN - Extrator + Classificador\n",
        "\n",
        "### ğŸ—ï¸ Estrutura Geral\n",
        "\n",
        "Uma CNN completa Ã© composta por **duas partes principais**:\n",
        "\n",
        "#### 1ï¸âƒ£ **Extrator de CaracterÃ­sticas** (Feature Extractor)\n",
        "- **FunÃ§Ã£o**: Detectar padrÃµes visuais hierÃ¡rquicos\n",
        "- **Componentes**: Conv2D + Pooling + AtivaÃ§Ã£o\n",
        "- **Processo**: Bordas â†’ Texturas â†’ Formas â†’ Objetos\n",
        "- **SaÃ­da**: Feature maps com caracterÃ­sticas extraÃ­das\n",
        "\n",
        "#### 2ï¸âƒ£ **Classificador** (Classifier)  \n",
        "- **FunÃ§Ã£o**: Tomar decisÃ£o baseada nas caracterÃ­sticas\n",
        "- **Componentes**: Flatten + Dense layers (MLP)\n",
        "- **Processo**: Features â†’ CombinaÃ§Ãµes â†’ Probabilidades\n",
        "- **SaÃ­da**: ClassificaÃ§Ã£o final\n",
        "\n",
        "### ğŸ¯ Arquitetura Visual\n",
        "\n",
        "<img src=\"https://github.com/arnaldojr/DisruptiveArchitectures/blob/master/material/aulas/lab08/convnet.png?raw=1\" width=\"800px\">\n",
        "\n",
        "### ğŸ”„ Fluxo de Processamento\n",
        "\n",
        "```\n",
        "Imagem â†’ [Convâ†’ReLUâ†’Pool]Ã—N â†’ Flatten â†’ [Denseâ†’ReLU]Ã—M â†’ Softmax â†’ Classes\n",
        "  â†“             â†“                â†“            â†“              â†“\n",
        " Raw         Features         Vector      Hidden        Probabilities\n",
        "Pixels      Extraction      Formato 1D   Layers        por Classe\n",
        "```\n",
        "\n",
        "### ğŸ§® Hierarquia de CaracterÃ­sticas\n",
        "\n",
        "| Camada | Detecta | Exemplo |\n",
        "|--------|---------|---------|\n",
        "| **Conv1** | ğŸ” Bordas, linhas | `/`, `\\`, `â€”`, `|` |\n",
        "| **Conv2** | ğŸ”º Formas simples | Cantos, curvas |\n",
        "| **Conv3** | ğŸ¯ Partes de objetos | Olhos, rodas, janelas |\n",
        "| **Conv4+** | ğŸ–¼ï¸ Objetos completos | Faces, carros, casas |\n",
        "\n",
        "### âš¡ Por que essa DivisÃ£o?\n",
        "\n",
        "**Extrator (Convolucional):**\n",
        "- âœ… Preserva informaÃ§Ã£o espacial\n",
        "- âœ… Detecta padrÃµes locais\n",
        "- âœ… Invariante Ã  posiÃ§Ã£o\n",
        "- âœ… Compartilha pesos\n",
        "\n",
        "**Classificador (Dense):**\n",
        "- âœ… Combina informaÃ§Ã£o global\n",
        "- âœ… Aprende relaÃ§Ãµes complexas\n",
        "- âœ… Produz probabilidades\n",
        "- âœ… DecisÃ£o final"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e6cf8c6",
      "metadata": {},
      "source": [
        "## ğŸ‘— Parte 5: Exemplo PrÃ¡tico - Fashion MNIST com CNN\n",
        "\n",
        "### ğŸ¯ Por que Fashion MNIST?\n",
        "\n",
        "O **Fashion MNIST** Ã© um dataset ideal para aprender CNNs:\n",
        "\n",
        "- ğŸ“Š **Estrutura**: 70.000 imagens 28Ã—28 em escala de cinza\n",
        "- ğŸ‘• **Classes**: 10 tipos de roupas e acessÃ³rios\n",
        "- ğŸ“ **Complexidade**: Mais desafiador que dÃ­gitos do MNIST tradicional\n",
        "- ğŸ“ˆ **Benchmark**: PadrÃ£o da indÃºstria para testes iniciais\n",
        "\n",
        "### ğŸ·ï¸ Classes do Dataset:\n",
        "\n",
        "| CÃ³digo | Classe | Emoji | Exemplo |\n",
        "|--------|--------|-------|---------|\n",
        "| 0 | T-shirt/top | ğŸ‘• | Camisetas |\n",
        "| 1 | Trouser | ğŸ‘– | CalÃ§as |\n",
        "| 2 | Pullover | ğŸ§¥ | SuÃ©ter |\n",
        "| 3 | Dress | ğŸ‘— | Vestidos |\n",
        "| 4 | Coat | ğŸ§¥ | Casacos |\n",
        "| 5 | Sandal | ğŸ‘¡ | SandÃ¡lias |\n",
        "| 6 | Shirt | ğŸ‘” | Camisas |\n",
        "| 7 | Sneaker | ğŸ‘Ÿ | TÃªnis |\n",
        "| 8 | Bag | ğŸ‘œ | Bolsas |\n",
        "| 9 | Ankle boot | ğŸ‘¢ | Botas |\n",
        "\n",
        "### ğŸ”„ Nossa EstratÃ©gia:\n",
        "\n",
        "1. **Carregar e explorar** os dados\n",
        "2. **PrÃ©-processar** as imagens  \n",
        "3. **Construir CNN** progressivamente\n",
        "4. **Treinar e avaliar** o modelo\n",
        "5. **Visualizar resultados** e interpretar erros\n",
        "6. **Comparar** com MLP tradicional\n",
        "\n",
        "### ğŸ’¡ O que Esperamos Aprender:\n",
        "\n",
        "- Como CNNs **extraem caracterÃ­sticas** hierÃ¡rquicas\n",
        "- DiferenÃ§a de **performance** CNN vs MLP\n",
        "- **InterpretaÃ§Ã£o** dos filtros aprendidos\n",
        "- **AnÃ¡lise de erros** e limitaÃ§Ãµes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "723cd883",
      "metadata": {},
      "source": [
        "## ğŸ‘— Parte 5: Exemplo PrÃ¡tico - Fashion MNIST com CNN\n",
        "\n",
        "### ğŸ¯ Por que Fashion MNIST?\n",
        "\n",
        "O **Fashion MNIST** Ã© um dataset ideal para aprender CNNs:\n",
        "\n",
        "- ğŸ“Š **Estrutura**: 70.000 imagens 28Ã—28 em escala de cinza\n",
        "- ğŸ‘• **Classes**: 10 tipos de roupas e acessÃ³rios\n",
        "- ğŸ“ **Complexidade**: Mais desafiador que dÃ­gitos do MNIST tradicional\n",
        "- ğŸ“ˆ **Benchmark**: PadrÃ£o da indÃºstria para testes iniciais\n",
        "\n",
        "### ğŸ·ï¸ Classes do Dataset:\n",
        "\n",
        "| CÃ³digo | Classe | Emoji | Exemplo |\n",
        "|--------|--------|-------|---------|\n",
        "| 0 | T-shirt/top | ğŸ‘• | Camisetas |\n",
        "| 1 | Trouser | ğŸ‘– | CalÃ§as |\n",
        "| 2 | Pullover | ğŸ§¥ | SuÃ©ter |\n",
        "| 3 | Dress | ğŸ‘— | Vestidos |\n",
        "| 4 | Coat | ğŸ§¥ | Casacos |\n",
        "| 5 | Sandal | ğŸ‘¡ | SandÃ¡lias |\n",
        "| 6 | Shirt | ğŸ‘” | Camisas |\n",
        "| 7 | Sneaker | ğŸ‘Ÿ | TÃªnis |\n",
        "| 8 | Bag | ğŸ‘œ | Bolsas |\n",
        "| 9 | Ankle boot | ğŸ‘¢ | Botas |\n",
        "\n",
        "### ğŸ”„ Nossa EstratÃ©gia:\n",
        "\n",
        "1. **Carregar e explorar** os dados\n",
        "2. **PrÃ©-processar** as imagens  \n",
        "3. **Construir CNN** progressivamente\n",
        "4. **Treinar e avaliar** o modelo\n",
        "5. **Visualizar resultados** e interpretar erros\n",
        "6. **Comparar** com MLP tradicional\n",
        "\n",
        "### ğŸ’¡ O que Esperamos Aprender:\n",
        "\n",
        "- Como CNNs **extraem caracterÃ­sticas** hierÃ¡rquicas\n",
        "- DiferenÃ§a de **performance** CNN vs MLP\n",
        "- **InterpretaÃ§Ã£o** dos filtros aprendidos\n",
        "- **AnÃ¡lise de erros** e limitaÃ§Ãµes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "50f08d5c",
      "metadata": {
        "id": "50f08d5c"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd13dd93",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ“Š CARREGANDO E EXPLORANDO O FASHION MNIST\n",
        "print(\"ğŸ“Š CARREGANDO FASHION MNIST\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Importa o dataset Fashion MNIST\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# InformaÃ§Ãµes bÃ¡sicas do dataset\n",
        "print(f\"ğŸ“ Formato dos dados de treino: {train_images.shape}\")\n",
        "print(f\"ğŸ“ Formato dos dados de teste: {test_images.shape}\")\n",
        "print(f\"ğŸ·ï¸ Formato dos rÃ³tulos de treino: {train_labels.shape}\")\n",
        "print(f\"ğŸ·ï¸ Formato dos rÃ³tulos de teste: {test_labels.shape}\")\n",
        "\n",
        "print(f\"\\nğŸ“Š ANÃLISE DOS DADOS:\")\n",
        "print(f\"   Total de imagens de treino: {len(train_images):,}\")\n",
        "print(f\"   Total de imagens de teste: {len(test_images):,}\")\n",
        "print(f\"   DimensÃ£o de cada imagem: {train_images[0].shape}\")\n",
        "print(f\"   Valores dos pixels: {train_images[0].min()} a {train_images[0].max()}\")\n",
        "print(f\"   NÃºmero de classes: {len(np.unique(train_labels))}\")\n",
        "\n",
        "# Nomes das classes\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "print(f\"\\nğŸ‘— CLASSES DO DATASET:\")\n",
        "for i, nome in enumerate(class_names):\n",
        "    count = np.sum(train_labels == i)\n",
        "    print(f\"   {i}: {nome} ({count:,} imagens)\")\n",
        "\n",
        "# NormalizaÃ§Ã£o: fundamental para CNNs!\n",
        "print(f\"\\nğŸ”„ NORMALIZANDO OS DADOS...\")\n",
        "print(\"Por que normalizar?\")\n",
        "print(\"   âœ… Acelera convergÃªncia do treinamento\")\n",
        "print(\"   âœ… Evita dominÃ¢ncia de pixels com valores altos\")\n",
        "print(\"   âœ… Melhora estabilidade numÃ©rica\")\n",
        "print(\"   âœ… PadrÃ£o para redes neurais\")\n",
        "\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "print(f\"   Novos valores dos pixels: {train_images[0].min():.1f} a {train_images[0].max():.1f}\")\n",
        "print(\"âœ… NormalizaÃ§Ã£o concluÃ­da!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96298330",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ”„ PREPARANDO DADOS PARA CNN\n",
        "print(\"ğŸ”„ PREPARANDO FORMATO PARA CNN\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "print(\"ğŸ“ RESHAPE NECESSÃRIO:\")\n",
        "print(f\"   Formato original: {train_images.shape}\")\n",
        "print(\"   Formato necessÃ¡rio para CNN: (samples, height, width, channels)\")\n",
        "print(\"   \")\n",
        "print(\"   ğŸ” Por que precisamos de 4 dimensÃµes?\")\n",
        "print(\"      â€¢ samples: nÃºmero de imagens\")\n",
        "print(\"      â€¢ height: altura da imagem\")  \n",
        "print(\"      â€¢ width: largura da imagem\")\n",
        "print(\"      â€¢ channels: canais de cor (1=grayscale, 3=RGB)\")\n",
        "\n",
        "# Reshape adicionando dimensÃ£o de canal\n",
        "train_images = train_images.reshape(-1, 28, 28, 1)\n",
        "test_images = test_images.reshape(-1, 28, 28, 1)\n",
        "\n",
        "print(f\"\\nâœ… APÃ“S RESHAPE:\")\n",
        "print(f\"   Dados de treino: {train_images.shape}\")\n",
        "print(f\"   Dados de teste: {test_images.shape}\")\n",
        "print(f\"   \")\n",
        "print(f\"   ğŸ“Š InterpretaÃ§Ã£o:\")\n",
        "print(f\"      â€¢ {train_images.shape[0]:,} imagens de treino\")\n",
        "print(f\"      â€¢ {train_images.shape[1]}Ã—{train_images.shape[2]} pixels cada\")\n",
        "print(f\"      â€¢ {train_images.shape[3]} canal (escala de cinza)\")\n",
        "\n",
        "# Visualizando algumas amostras\n",
        "print(f\"\\nğŸ–¼ï¸ VISUALIZANDO AMOSTRAS:\")\n",
        "fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
        "fig.suptitle('ğŸ‘— Amostras do Fashion MNIST', fontsize=16, fontweight='bold')\n",
        "\n",
        "for i in range(10):\n",
        "    ax = axes[i//5, i%5]\n",
        "    ax.imshow(train_images[i].reshape(28, 28), cmap='gray')\n",
        "    ax.set_title(f'{class_names[train_labels[i]]}')\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"âœ… Dados preparados para treinamento da CNN!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "084f6bc0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ—ï¸ CONSTRUINDO A CNN\n",
        "print(\"ğŸ—ï¸ CONSTRUINDO ARQUITETURA CNN\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "print(\"ğŸ¯ ESTRATÃ‰GIA DE DESIGN:\")\n",
        "print(\"   1ï¸âƒ£ ComeÃ§ar com CNN simples\")\n",
        "print(\"   2ï¸âƒ£ Camada Conv2D para extraÃ§Ã£o de caracterÃ­sticas\")\n",
        "print(\"   3ï¸âƒ£ MaxPooling para reduÃ§Ã£o dimensional\")\n",
        "print(\"   4ï¸âƒ£ Flatten para converter para 1D\")\n",
        "print(\"   5ï¸âƒ£ Dense layers para classificaÃ§Ã£o\")\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Arquitetura inicial simples\n",
        "model = keras.Sequential([\n",
        "    # ğŸ” EXTRATOR DE CARACTERÃSTICAS\n",
        "    layers.Conv2D(32, (3,3), activation='relu', padding='same', \n",
        "                  input_shape=(28, 28, 1), name='conv2d_1'),\n",
        "    layers.MaxPooling2D((2,2), name='maxpool_1'),\n",
        "    \n",
        "    # ğŸ§  CLASSIFICADOR  \n",
        "    layers.Flatten(name='flatten'),\n",
        "    layers.Dense(128, activation='relu', name='dense_1'),\n",
        "    layers.Dense(10, activation='softmax', name='output')  # 10 classes\n",
        "])\n",
        "\n",
        "print(\"ğŸ“‹ RESUMO DA ARQUITETURA:\")\n",
        "model.summary()\n",
        "\n",
        "print(f\"\\nğŸ” ANÃLISE DETALHADA:\")\n",
        "print(f\"   ğŸ“ Input: (28, 28, 1) - Imagem grayscale\")\n",
        "print(f\"   ğŸ”„ Conv2D: 32 filtros 3Ã—3 â†’ (28, 28, 32)\")\n",
        "print(f\"   ğŸŠ MaxPool: 2Ã—2 â†’ (14, 14, 32)\")\n",
        "print(f\"   ğŸ“ Flatten: â†’ ({14*14*32},)\")\n",
        "print(f\"   ğŸ§  Dense: 128 neurÃ´nios â†’ (128,)\")  \n",
        "print(f\"   ğŸ¯ Output: 10 classes â†’ (10,)\")\n",
        "\n",
        "# Calculando parÃ¢metros manualmente para compreensÃ£o\n",
        "conv_params = (3*3*1*32) + 32  # kernel Ã— input_channels Ã— filters + bias\n",
        "dense1_params = (14*14*32*128) + 128  # input Ã— neurons + bias\n",
        "dense2_params = (128*10) + 10  # input Ã— neurons + bias\n",
        "\n",
        "print(f\"\\nğŸ§® CÃLCULO MANUAL DE PARÃ‚METROS:\")\n",
        "print(f\"   Conv2D: {conv_params:,} parÃ¢metros\")\n",
        "print(f\"   Dense 1: {dense1_params:,} parÃ¢metros\")\n",
        "print(f\"   Dense 2: {dense2_params:,} parÃ¢metros\")\n",
        "print(f\"   Total calculado: {conv_params + dense1_params + dense2_params:,}\")\n",
        "print(f\"   Total do modelo: {model.count_params():,}\")\n",
        "\n",
        "print(f\"\\nğŸ’¡ OBSERVAÃ‡Ã•ES:\")\n",
        "print(\"   âœ… A maioria dos parÃ¢metros estÃ¡ nas camadas Dense\")\n",
        "print(\"   âœ… Conv2D tem poucos parÃ¢metros mas extrai caracterÃ­sticas importantes\")\n",
        "print(\"   âœ… MaxPooling nÃ£o tem parÃ¢metros treinÃ¡veis\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "329f1faa",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ¯ COMPILAÃ‡ÃƒO E TREINAMENTO DO MODELO\n",
        "print(\"ğŸ¯ COMPILAÃ‡ÃƒO DO MODELO\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "print(\"âš™ï¸ CONFIGURAÃ‡Ã•ES DE TREINAMENTO:\")\n",
        "print(\"   ğŸ”§ Optimizer: Adam (adaptativo, eficiente)\")\n",
        "print(\"   ğŸ“‰ Loss: sparse_categorical_crossentropy (para mÃºltiplas classes)\")\n",
        "print(\"   ğŸ“Š Metrics: accuracy (para acompanhar performance)\")\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"âœ… Modelo compilado com sucesso!\")\n",
        "\n",
        "print(f\"\\nğŸš€ INICIANDO TREINAMENTO:\")\n",
        "print(f\"   ğŸ“š Ã‰pocas: 5 (poucas para demonstraÃ§Ã£o)\")\n",
        "print(f\"   ğŸ“Š Validation split: 20% dos dados de treino\")\n",
        "print(f\"   ğŸ¯ Objetivo: Entender o processo de aprendizado\")\n",
        "\n",
        "print(f\"\\nâ±ï¸ Treinamento em andamento...\")\n",
        "\n",
        "# Treinamento com mais Ã©pocas e monitoramento\n",
        "epochs_hist = model.fit(\n",
        "    train_images, train_labels, \n",
        "    epochs=5,\n",
        "    validation_split=0.2,\n",
        "    verbose=1,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "print(f\"\\nğŸ‰ TREINAMENTO CONCLUÃDO!\")\n",
        "print(f\"âœ… Modelo treinado por {len(epochs_hist.history['loss'])} Ã©pocas\")\n",
        "print(f\"ğŸ“ˆ Ãšltima acurÃ¡cia de treino: {epochs_hist.history['accuracy'][-1]:.3f}\")\n",
        "print(f\"ğŸ“Š Ãšltima acurÃ¡cia de validaÃ§Ã£o: {epochs_hist.history['val_accuracy'][-1]:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc0ef950",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ“ˆ VISUALIZAÃ‡ÃƒO DO TREINAMENTO\n",
        "print(\"ğŸ“ˆ ANÃLISE DO TREINAMENTO\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Convertendo histÃ³rico para DataFrame para anÃ¡lise\n",
        "import pandas as pd\n",
        "history_df = pd.DataFrame(epochs_hist.history)\n",
        "\n",
        "print(\"ğŸ” MÃ‰TRICAS POR Ã‰POCA:\")\n",
        "print(history_df.round(4))\n",
        "\n",
        "# VisualizaÃ§Ã£o aprimorada dos grÃ¡ficos\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# GrÃ¡fico de Loss\n",
        "ax1.plot(history_df['loss'], 'b-', label='Loss de Treino', linewidth=2)\n",
        "ax1.plot(history_df['val_loss'], 'r-', label='Loss de ValidaÃ§Ã£o', linewidth=2)\n",
        "ax1.set_title('ğŸ“‰ EvoluÃ§Ã£o da FunÃ§Ã£o de Loss', fontsize=14, fontweight='bold')\n",
        "ax1.set_xlabel('Ã‰poca')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# GrÃ¡fico de AcurÃ¡cia\n",
        "ax2.plot(history_df['accuracy'], 'b-', label='AcurÃ¡cia de Treino', linewidth=2)\n",
        "ax2.plot(history_df['val_accuracy'], 'r-', label='AcurÃ¡cia de ValidaÃ§Ã£o', linewidth=2)\n",
        "ax2.set_title('ğŸ“Š EvoluÃ§Ã£o da AcurÃ¡cia', fontsize=14, fontweight='bold')\n",
        "ax2.set_xlabel('Ã‰poca')\n",
        "ax2.set_ylabel('AcurÃ¡cia')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# AnÃ¡lise dos resultados\n",
        "print(f\"\\nğŸ” ANÃLISE DOS RESULTADOS:\")\n",
        "print(f\"   ğŸ“ˆ Melhoria no treino: {history_df['accuracy'].iloc[-1] - history_df['accuracy'].iloc[0]:.3f}\")\n",
        "print(f\"   ğŸ“Š Melhoria na validaÃ§Ã£o: {history_df['val_accuracy'].iloc[-1] - history_df['val_accuracy'].iloc[0]:.3f}\")\n",
        "\n",
        "# VerificaÃ§Ã£o de overfitting\n",
        "gap_inicial = history_df['accuracy'].iloc[0] - history_df['val_accuracy'].iloc[0]\n",
        "gap_final = history_df['accuracy'].iloc[-1] - history_df['val_accuracy'].iloc[-1]\n",
        "\n",
        "print(f\"\\nğŸ¯ DIAGNÃ“STICO DE OVERFITTING:\")\n",
        "print(f\"   Gap inicial (treino-val): {gap_inicial:.3f}\")\n",
        "print(f\"   Gap final (treino-val): {gap_final:.3f}\")\n",
        "\n",
        "if abs(gap_final) < 0.05:\n",
        "    print(\"   âœ… Modelo bem balanceado!\")\n",
        "elif gap_final > 0.1:\n",
        "    print(\"   âš ï¸ PossÃ­vel overfitting - considere regularizaÃ§Ã£o\")\n",
        "elif gap_final < -0.05:\n",
        "    print(\"   ğŸ”„ Modelo pode ter mais capacidade - considere treinar mais\")\n",
        "else:\n",
        "    print(\"   ğŸ‘ Desempenho razoÃ¡vel\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "056dc121",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ¯ AVALIAÃ‡ÃƒO COMPLETA DO MODELO\n",
        "print(\"ğŸ¯ AVALIAÃ‡ÃƒO FINAL DO MODELO\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "print(\"ğŸ“Š AVALIANDO PERFORMANCE...\")\n",
        "\n",
        "# AvaliaÃ§Ã£o nos dados de treino e teste\n",
        "train_loss, train_acc = model.evaluate(train_images, train_labels, verbose=0)\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=0)\n",
        "\n",
        "print(f\"\\nğŸ“ˆ RESULTADOS FINAIS:\")\n",
        "print(f\"   ğŸ“ Treino - Loss: {train_loss:.4f} | AcurÃ¡cia: {train_acc:.4f} ({train_acc*100:.1f}%)\")\n",
        "print(f\"   ğŸ§ª Teste  - Loss: {test_loss:.4f} | AcurÃ¡cia: {test_acc:.4f} ({test_acc*100:.1f}%)\")\n",
        "\n",
        "# AnÃ¡lise de overfitting\n",
        "overfitting_gap = train_acc - test_acc\n",
        "print(f\"\\nğŸ” ANÃLISE DE GENERALIZAÃ‡ÃƒO:\")\n",
        "print(f\"   Gap treino-teste: {overfitting_gap:.4f}\")\n",
        "\n",
        "if overfitting_gap < 0.02:\n",
        "    print(\"   âœ… Excelente generalizaÃ§Ã£o!\")\n",
        "elif overfitting_gap < 0.05:\n",
        "    print(\"   ğŸ‘ Boa generalizaÃ§Ã£o\")\n",
        "elif overfitting_gap < 0.1:\n",
        "    print(\"   âš ï¸ Leve overfitting\")\n",
        "else:\n",
        "    print(\"   ğŸš« Overfitting significativo - modelo memorizou o treino\")\n",
        "\n",
        "# ComparaÃ§Ã£o com baseline\n",
        "print(f\"\\nğŸ¯ COMPARAÃ‡ÃƒO COM BASELINES:\")\n",
        "random_acc = 1/10  # 10 classes, chute aleatÃ³rio\n",
        "print(f\"   ğŸ² Baseline aleatÃ³rio: {random_acc:.3f} ({random_acc*100:.1f}%)\")\n",
        "print(f\"   ğŸš€ Melhoria sobre baseline: {(test_acc/random_acc):.1f}x\")\n",
        "\n",
        "# InterpretaÃ§Ã£o do resultado\n",
        "if test_acc > 0.85:\n",
        "    print(\"   ğŸ† Performance excelente!\")\n",
        "elif test_acc > 0.75:\n",
        "    print(\"   âœ… Performance boa\")\n",
        "elif test_acc > 0.65:\n",
        "    print(\"   ğŸ‘ Performance razoÃ¡vel\")\n",
        "else:\n",
        "    print(\"   âš ï¸ Performance baixa - modelo precisa melhorar\")\n",
        "\n",
        "print(f\"\\nğŸ’¡ OBSERVAÃ‡Ã•ES:\")\n",
        "print(\"   â€¢ Fashion MNIST Ã© mais desafiador que MNIST dÃ­gitos\")\n",
        "print(\"   â€¢ CNNs simples jÃ¡ superam MLPs tradicionais\")\n",
        "print(\"   â€¢ Margem para melhoria com arquiteturas mais complexas\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea5856b9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ”® FAZENDO PREDIÃ‡Ã•ES\n",
        "print(\"ğŸ”® GERANDO PREDIÃ‡Ã•ES DO MODELO\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "print(\"ğŸ¯ Fazendo prediÃ§Ãµes no conjunto de teste...\")\n",
        "predictions = model.predict(test_images, verbose=0)\n",
        "\n",
        "print(f\"âœ… PrediÃ§Ãµes concluÃ­das!\")\n",
        "print(f\"ğŸ“Š Formato das prediÃ§Ãµes: {predictions.shape}\")\n",
        "print(f\"ğŸ’¡ Cada linha contÃ©m probabilidades para as 10 classes\")\n",
        "\n",
        "# Analisando as prediÃ§Ãµes\n",
        "print(f\"\\nğŸ” ANÃLISE DAS PREDIÃ‡Ã•ES:\")\n",
        "max_probs = np.max(predictions, axis=1)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "print(f\"   ğŸ“ˆ ConfianÃ§a mÃ©dia: {np.mean(max_probs):.3f}\")\n",
        "print(f\"   ğŸ“Š ConfianÃ§a mÃ­nima: {np.min(max_probs):.3f}\")\n",
        "print(f\"   ğŸ“Š ConfianÃ§a mÃ¡xima: {np.max(max_probs):.3f}\")\n",
        "\n",
        "# Histograma de confianÃ§a\n",
        "print(f\"\\nğŸ“Š DISTRIBUIÃ‡ÃƒO DE CONFIANÃ‡A:\")\n",
        "confidence_ranges = [(0.0, 0.5), (0.5, 0.7), (0.7, 0.9), (0.9, 1.0)]\n",
        "for low, high in confidence_ranges:\n",
        "    count = np.sum((max_probs >= low) & (max_probs < high))\n",
        "    percentage = count / len(max_probs) * 100\n",
        "    print(f\"   {low:.1f}-{high:.1f}: {count:,} prediÃ§Ãµes ({percentage:.1f}%)\")\n",
        "\n",
        "print(f\"\\nğŸ’¡ INTERPRETAÃ‡ÃƒO:\")\n",
        "high_confidence = np.sum(max_probs > 0.9)\n",
        "low_confidence = np.sum(max_probs < 0.5)\n",
        "print(f\"   âœ… Alta confianÃ§a (>90%): {high_confidence} prediÃ§Ãµes\")\n",
        "print(f\"   âš ï¸ Baixa confianÃ§a (<50%): {low_confidence} prediÃ§Ãµes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84662bf4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ” ANÃLISE DETALHADA DE PREDIÃ‡Ã•ES INDIVIDUAIS\n",
        "print(\"ğŸ” ANÃLISE DE PREDIÃ‡Ã•ES INDIVIDUAIS\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Escolhendo alguns exemplos para anÃ¡lise\n",
        "exemplos = [42, 1000, 2500, 4000, 7500]\n",
        "\n",
        "for i, item in enumerate(exemplos):\n",
        "    print(f\"\\nğŸ“Š EXEMPLO {i+1} (Ãndice {item}):\")\n",
        "    print(\"-\" * 30)\n",
        "    \n",
        "    # InformaÃ§Ãµes da prediÃ§Ã£o\n",
        "    classe_predita = np.argmax(predictions[item])\n",
        "    confianca = 100 * np.max(predictions[item])\n",
        "    classe_real = test_labels[item]\n",
        "    \n",
        "    print(f\"   ğŸ¤– PrediÃ§Ã£o: {class_names[classe_predita]} (confianÃ§a: {confianca:.1f}%)\")\n",
        "    print(f\"   âœ… Real: {class_names[classe_real]}\")\n",
        "    \n",
        "    # Verificando se acertou\n",
        "    if classe_predita == classe_real:\n",
        "        print(f\"   ğŸ¯ ACERTOU! âœ“\")\n",
        "    else:\n",
        "        print(f\"   âŒ ERROU! âœ—\")\n",
        "    \n",
        "    # Top 3 prediÃ§Ãµes\n",
        "    top3_indices = np.argsort(predictions[item])[-3:][::-1]\n",
        "    print(f\"   ğŸ† Top 3 prediÃ§Ãµes:\")\n",
        "    for j, idx in enumerate(top3_indices):\n",
        "        prob = predictions[item][idx] * 100\n",
        "        print(f\"      {j+1}Âº: {class_names[idx]} ({prob:.1f}%)\")\n",
        "\n",
        "# EstatÃ­sticas gerais\n",
        "acertos = np.sum(predicted_classes == test_labels)\n",
        "total = len(test_labels)\n",
        "acuracia_final = acertos / total\n",
        "\n",
        "print(f\"\\nğŸ“ˆ ESTATÃSTICAS GERAIS:\")\n",
        "print(f\"   âœ… Acertos: {acertos:,} de {total:,}\")\n",
        "print(f\"   ğŸ“Š AcurÃ¡cia: {acuracia_final:.3f} ({acuracia_final*100:.1f}%)\")\n",
        "print(f\"   âŒ Erros: {total - acertos:,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "9f03e7ee",
      "metadata": {
        "id": "9f03e7ee"
      },
      "outputs": [],
      "source": [
        "def plot_image(i, predictions_array, true_label, img):\n",
        "  predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "\n",
        "  plt.imshow(img, cmap=plt.cm.binary)\n",
        "\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "  if predicted_label == true_label:\n",
        "    color = 'blue'\n",
        "  else:\n",
        "    color = 'red'\n",
        "\n",
        "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
        "                                100*np.max(predictions_array),\n",
        "                                class_names[true_label]),\n",
        "                                color=color)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "3029fbb5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "3029fbb5",
        "outputId": "781828d5-03b4-48da-f557-aa919c93bbff"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(item, predictions, test_labels, test_images)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99cdcc91",
      "metadata": {},
      "source": [
        "## ğŸ¯ Desafio 3: Implementando a LeNet-5 - A CNN Pioneira\n",
        "\n",
        "### ğŸ“š Contexto HistÃ³rico\n",
        "\n",
        "A **LeNet-5**, desenvolvida por **Yann LeCun** em 1998, foi uma das primeiras CNNs bem-sucedidas e estabeleceu muitos dos princÃ­pios fundamentais ainda usados hoje.\n",
        "\n",
        "### ğŸ—ï¸ Arquitetura da LeNet-5\n",
        "\n",
        "<img src=\"https://github.com/arnaldojr/DisruptiveArchitectures/blob/master/material/aulas/lab08/lenet.png?raw=1\" width=\"800px\">\n",
        "\n",
        "**EspecificaÃ§Ãµes originais:**\n",
        "```\n",
        "INPUT(32Ã—32Ã—1) â†’ CONV1(28Ã—28Ã—6) â†’ POOL1(14Ã—14Ã—6) â†’ \n",
        "CONV2(10Ã—10Ã—16) â†’ POOL2(5Ã—5Ã—16) â†’ FC1(120) â†’ FC2(84) â†’ OUTPUT(10)\n",
        "```\n",
        "\n",
        "### ğŸ¯ CaracterÃ­sticas da LeNet-5:\n",
        "\n",
        "1. **Entrada**: 32Ã—32 pixels (grayscale)\n",
        "2. **C1**: 6 filtros 5Ã—5, sem padding\n",
        "3. **S2**: Subsampling (average pooling) 2Ã—2\n",
        "4. **C3**: 16 filtros 5Ã—5\n",
        "5. **S4**: Subsampling 2Ã—2\n",
        "6. **FC5**: 120 neurÃ´nios\n",
        "7. **FC6**: 84 neurÃ´nios\n",
        "8. **OUTPUT**: 10 classes\n",
        "\n",
        "### ğŸ’¡ Desafio para VocÃª:\n",
        "\n",
        "**Implemente a LeNet-5 adaptada para Fashion MNIST (28Ã—28) seguindo estas especificaÃ§Ãµes:**\n",
        "\n",
        "```python\n",
        "# Sua implementaÃ§Ã£o deve seguir esta estrutura:\n",
        "def create_lenet5_fashion():\n",
        "    model = keras.Sequential([\n",
        "        # C1: Convolutional Layer\n",
        "        # S2: Subsampling Layer (Pooling)\n",
        "        # C3: Convolutional Layer\n",
        "        # S4: Subsampling Layer\n",
        "        # Flatten\n",
        "        # FC5: Dense Layer (120 neurons)\n",
        "        # FC6: Dense Layer (84 neurons)\n",
        "        # Output Layer (10 classes)\n",
        "    ])\n",
        "    return model\n",
        "```\n",
        "\n",
        "### ğŸ“‹ Requisitos do Desafio:\n",
        "\n",
        "1. âœ… **Implementar LeNet-5** seguindo a arquitetura original\n",
        "2. âœ… **Comparar com sua CNN simples** anterior\n",
        "3. âœ… **Analisar diferenÃ§as** de performance\n",
        "4. âœ… **Documentar observaÃ§Ãµes** sobre cada camada\n",
        "5. âœ… **Visualizar resultados** e mÃ©tricas\n",
        "\n",
        "### ğŸ¯ MÃ©tricas de Sucesso:\n",
        "\n",
        "- **AcurÃ¡cia > 85%** no Fashion MNIST\n",
        "- **Menos overfitting** que a CNN simples\n",
        "- **AnÃ¡lise comparativa** detalhada\n",
        "- **CÃ³digo bem documentado**\n",
        "\n",
        "### ğŸ’­ Perguntas para ReflexÃ£o:\n",
        "\n",
        "1. **Por que LeNet-5 tem 2 camadas convolucionais?**\n",
        "2. **Qual a vantagem de ter camadas FC decrescentes (120â†’84â†’10)?**\n",
        "3. **Como a LeNet-5 se compara com CNNs modernas?**\n",
        "4. **O que vocÃª mudaria na arquitetura original?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4959834f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ¯ DESAFIO 3: SUA IMPLEMENTAÃ‡ÃƒO DA LENET-5\n",
        "print(\"ğŸ¯ DESAFIO 3: IMPLEMENTANDO LENET-5\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "def create_lenet5_fashion():\n",
        "    \"\"\"\n",
        "    Implementa a arquitetura LeNet-5 adaptada para Fashion MNIST\n",
        "    \n",
        "    Arquitetura:\n",
        "    - Conv2D: 6 filtros 5x5\n",
        "    - AvgPool2D: 2x2\n",
        "    - Conv2D: 16 filtros 5x5  \n",
        "    - AvgPool2D: 2x2\n",
        "    - Flatten\n",
        "    - Dense: 120 neurÃ´nios\n",
        "    - Dense: 84 neurÃ´nios\n",
        "    - Dense: 10 classes (softmax)\n",
        "    \"\"\"\n",
        "    \n",
        "    print(\"ğŸ—ï¸ Construindo LeNet-5...\")\n",
        "    \n",
        "    # COMPLETE A IMPLEMENTAÃ‡ÃƒO AQUI:\n",
        "    # ====================================\n",
        "    \n",
        "    model = keras.Sequential([\n",
        "        # ğŸ” PRIMEIRA CAMADA CONVOLUCIONAL\n",
        "        # layers.Conv2D(?, (?,?), activation='?', input_shape=(28,28,1)),\n",
        "        \n",
        "        # ğŸŠ PRIMEIRA CAMADA DE POOLING  \n",
        "        # layers.AveragePooling2D((?,?)),\n",
        "        \n",
        "        # ğŸ” SEGUNDA CAMADA CONVOLUCIONAL\n",
        "        # layers.Conv2D(?, (?,?), activation='?'),\n",
        "        \n",
        "        # ğŸŠ SEGUNDA CAMADA DE POOLING\n",
        "        # layers.AveragePooling2D((?,?)),\n",
        "        \n",
        "        # ğŸ“ FLATTEN\n",
        "        # layers.Flatten(),\n",
        "        \n",
        "        # ğŸ§  CAMADAS DENSAS\n",
        "        # layers.Dense(?, activation='?'),\n",
        "        # layers.Dense(?, activation='?'),\n",
        "        # layers.Dense(?, activation='?')  # SaÃ­da\n",
        "    ])\n",
        "    \n",
        "    # ====================================\n",
        "    \n",
        "    return model\n",
        "\n",
        "# TESTE SUA IMPLEMENTAÃ‡ÃƒO:\n",
        "print(\"ğŸ§ª TESTANDO SUA IMPLEMENTAÃ‡ÃƒO:\")\n",
        "\n",
        "# Descomente as linhas abaixo apÃ³s implementar:\n",
        "# lenet5_model = create_lenet5_fashion()\n",
        "# lenet5_model.summary()\n",
        "\n",
        "# print(f\"\\nğŸ“Š COMPARAÃ‡ÃƒO COM CNN SIMPLES:\")\n",
        "# print(f\"   CNN Simples: {model.count_params():,} parÃ¢metros\")\n",
        "# print(f\"   LeNet-5: {lenet5_model.count_params():,} parÃ¢metros\")\n",
        "\n",
        "print(\"\\nğŸ’¡ DICAS:\")\n",
        "print(\"   â€¢ Use activation='tanh' para ser mais fiel ao original\")\n",
        "print(\"   â€¢ Average pooling era usado na LeNet-5 original\")\n",
        "print(\"   â€¢ Analise o nÃºmero de parÃ¢metros em cada camada\")\n",
        "print(\"   â€¢ Compare a performance com sua CNN simples\")\n",
        "\n",
        "print(\"\\nğŸ¯ APÃ“S IMPLEMENTAR, TREINE E COMPARE:\")\n",
        "print(\"   1. Compile o modelo\")\n",
        "print(\"   2. Treine por algumas Ã©pocas\")\n",
        "print(\"   3. Compare mÃ©tricas com CNN simples\")\n",
        "print(\"   4. Analise diferenÃ§as arquiteturais\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62169f5d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ” ANÃLISE COMPARATIVA (Complete apÃ³s implementar)\n",
        "print(\"ğŸ” ANÃLISE COMPARATIVA: CNN SIMPLES vs LENET-5\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Esta seÃ§Ã£o deve ser preenchida apÃ³s vocÃª implementar a LeNet-5\n",
        "\n",
        "print(\"ğŸ“Š RESULTADOS COMPARATIVOS:\")\n",
        "print(\"=\" * 30)\n",
        "\n",
        "# Exemplo de template para suas anÃ¡lises:\n",
        "comparacao = {\n",
        "    'MÃ©trica': ['ParÃ¢metros', 'AcurÃ¡cia Treino', 'AcurÃ¡cia Teste', 'Tempo Treino', 'Overfitting'],\n",
        "    'CNN Simples': ['?', '?', '?', '?', '?'],\n",
        "    'LeNet-5': ['?', '?', '?', '?', '?']\n",
        "}\n",
        "\n",
        "print(\"| MÃ©trica | CNN Simples | LeNet-5 |\")\n",
        "print(\"|---------|-------------|---------|\")\n",
        "for i, metrica in enumerate(comparacao['MÃ©trica']):\n",
        "    print(f\"| {metrica} | {comparacao['CNN Simples'][i]} | {comparacao['LeNet-5'][i]} |\")\n",
        "\n",
        "print(f\"\\nğŸ¯ SUAS CONCLUSÃ•ES:\")\n",
        "print(\"=\" * 20)\n",
        "print(\"1. Qual modelo teve melhor performance? Por quÃª?\")\n",
        "print(\"   Resposta: ________________________________\")\n",
        "print(\"\")\n",
        "print(\"2. Qual a principal diferenÃ§a arquitetural?\")\n",
        "print(\"   Resposta: ________________________________\")\n",
        "print(\"\")\n",
        "print(\"3. LeNet-5 ainda Ã© relevante hoje? Por quÃª?\")\n",
        "print(\"   Resposta: ________________________________\")\n",
        "print(\"\")\n",
        "print(\"4. O que vocÃª mudaria na LeNet-5 original?\")\n",
        "print(\"   Resposta: ________________________________\")\n",
        "\n",
        "print(f\"\\nğŸ† PRÃ“XIMOS PASSOS:\")\n",
        "print(\"   â€¢ Experimente diferentes funÃ§Ãµes de ativaÃ§Ã£o\")\n",
        "print(\"   â€¢ Teste com dropout para reduzir overfitting\")\n",
        "print(\"   â€¢ Implemente data augmentation\")\n",
        "print(\"   â€¢ Compare com arquiteturas modernas\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3a3c9d0",
      "metadata": {},
      "source": [
        "## ğŸš€ Desafio Extra: CNN para CIFAR-10\n",
        "\n",
        "### ğŸ¯ Por que CIFAR-10 Ã© Mais Desafiador?\n",
        "\n",
        "O **CIFAR-10** Ã© significativamente mais complexo que Fashion MNIST:\n",
        "\n",
        "| Aspecto | Fashion MNIST | CIFAR-10 |\n",
        "|---------|---------------|----------|\n",
        "| **ResoluÃ§Ã£o** | 28Ã—28 | 32Ã—32 |\n",
        "| **Canais** | 1 (grayscale) | 3 (RGB) |\n",
        "| **Classes** | 10 roupas | 10 objetos |\n",
        "| **Complexidade** | Texturas simples | Objetos naturais |\n",
        "| **Variabilidade** | Baixa | Alta |\n",
        "\n",
        "### ğŸ·ï¸ Classes do CIFAR-10:\n",
        "- âœˆï¸ **airplane** | ğŸš— **automobile** | ğŸ¦ **bird** | ğŸ± **cat** | ğŸ¦Œ **deer**\n",
        "- ğŸ¶ **dog** | ğŸ¸ **frog** | ğŸ´ **horse** | ğŸš¢ **ship** | ğŸš› **truck**\n",
        "\n",
        "### ğŸ’¡ EstratÃ©gias Recomendadas:\n",
        "\n",
        "#### 1ï¸âƒ£ **Arquitetura Mais Profunda**\n",
        "```python\n",
        "# CNN mais robusta para CIFAR-10\n",
        "model = Sequential([\n",
        "    # Bloco 1\n",
        "    Conv2D(32, (3,3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(32, (3,3), activation='relu', padding='same'),\n",
        "    MaxPooling2D((2,2)),\n",
        "    Dropout(0.25),\n",
        "    \n",
        "    # Bloco 2  \n",
        "    Conv2D(64, (3,3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(64, (3,3), activation='relu', padding='same'),\n",
        "    MaxPooling2D((2,2)),\n",
        "    Dropout(0.25),\n",
        "    \n",
        "    # Classificador\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "```\n",
        "\n",
        "#### 2ï¸âƒ£ **TÃ©cnicas Essenciais**\n",
        "- **Data Augmentation**: RotaÃ§Ã£o, flip, zoom\n",
        "- **Batch Normalization**: Estabiliza treinamento\n",
        "- **Dropout**: Reduz overfitting\n",
        "- **Learning Rate Scheduling**: Melhora convergÃªncia\n",
        "\n",
        "#### 3ï¸âƒ£ **MÃ©tricas de Sucesso**\n",
        "- ğŸ¯ **Baseline**: >70% acurÃ¡cia\n",
        "- ğŸš€ **Bom**: >80% acurÃ¡cia  \n",
        "- ğŸ† **Excelente**: >85% acurÃ¡cia\n",
        "\n",
        "### ğŸ¯ Seu Desafio:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "610e3e26",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸš€ DESAFIO EXTRA: CNN PARA CIFAR-10\n",
        "print(\"ğŸš€ DESAFIO EXTRA: CNN PARA CIFAR-10\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Passo 1: Carregamento e PreparaÃ§Ã£o dos Dados\n",
        "print(\"ğŸ“Š CARREGANDO CIFAR-10...\")\n",
        "\n",
        "# COMPLETE AQUI:\n",
        "# ===============================================\n",
        "\n",
        "# (x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "# print(f\"Formato dos dados: {x_train.shape}\")\n",
        "# print(f\"Classes: {np.unique(y_train)}\")\n",
        "\n",
        "# # NormalizaÃ§Ã£o\n",
        "# x_train = x_train.astype('float32') / 255.0\n",
        "# x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# # Nomes das classes\n",
        "# cifar10_classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "#                   'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "# ===============================================\n",
        "\n",
        "print(\"âœ… Dados carregados e normalizados!\")\n",
        "\n",
        "# Passo 2: VisualizaÃ§Ã£o dos Dados\n",
        "print(\"\\nğŸ–¼ï¸ VISUALIZANDO AMOSTRAS DO CIFAR-10:\")\n",
        "\n",
        "# COMPLETE A VISUALIZAÃ‡ÃƒO:\n",
        "# ===============================================\n",
        "\n",
        "# fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
        "# for i in range(10):\n",
        "#     ax = axes[i//5, i%5]\n",
        "#     ax.imshow(x_train[i])\n",
        "#     ax.set_title(f'{cifar10_classes[y_train[i][0]]}')\n",
        "#     ax.axis('off')\n",
        "# plt.show()\n",
        "\n",
        "# ===============================================\n",
        "\n",
        "# Passo 3: ConstruÃ§Ã£o da CNN\n",
        "print(\"\\nğŸ—ï¸ CONSTRUINDO CNN PARA CIFAR-10:\")\n",
        "\n",
        "def create_cifar10_cnn():\n",
        "    \"\"\"\n",
        "    Crie uma CNN robusta para CIFAR-10\n",
        "    \n",
        "    Requisitos:\n",
        "    - Pelo menos 3 blocos convolucionais\n",
        "    - Batch Normalization\n",
        "    - Dropout para regularizaÃ§Ã£o\n",
        "    - Data Augmentation\n",
        "    \"\"\"\n",
        "    \n",
        "    # COMPLETE SUA IMPLEMENTAÃ‡ÃƒO:\n",
        "    # ===================================\n",
        "    \n",
        "    # model = keras.Sequential([\n",
        "    #     # Bloco 1: Conv + BatchNorm + Pool + Dropout\n",
        "    #     \n",
        "    #     # Bloco 2: Conv + BatchNorm + Pool + Dropout\n",
        "    #     \n",
        "    #     # Bloco 3: Conv + BatchNorm + Pool + Dropout\n",
        "    #     \n",
        "    #     # Classificador: Flatten + Dense + Dropout + Output\n",
        "    # ])\n",
        "    \n",
        "    # ===================================\n",
        "    \n",
        "    return None  # Substitua por seu modelo\n",
        "\n",
        "# Passo 4: Data Augmentation\n",
        "print(\"\\nğŸ”„ CONFIGURANDO DATA AUGMENTATION:\")\n",
        "\n",
        "# COMPLETE A CONFIGURAÃ‡ÃƒO:\n",
        "# ===============================================\n",
        "\n",
        "# datagen = ImageDataGenerator(\n",
        "#     rotation_range=15,\n",
        "#     width_shift_range=0.1,\n",
        "#     height_shift_range=0.1,\n",
        "#     horizontal_flip=True,\n",
        "#     zoom_range=0.1\n",
        "# )\n",
        "\n",
        "# ===============================================\n",
        "\n",
        "# Passo 5: Treinamento\n",
        "print(\"\\nğŸš€ TREINAMENTO DO MODELO:\")\n",
        "\n",
        "# COMPLETE O TREINAMENTO:\n",
        "# ===============================================\n",
        "\n",
        "# model = create_cifar10_cnn()\n",
        "# model.compile(\n",
        "#     optimizer='adam',\n",
        "#     loss='sparse_categorical_crossentropy', \n",
        "#     metrics=['accuracy']\n",
        "# )\n",
        "\n",
        "# # Callbacks\n",
        "# callbacks = [\n",
        "#     keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
        "#     keras.callbacks.ReduceLROnPlateau(factor=0.2, patience=5)\n",
        "# ]\n",
        "\n",
        "# # Treinamento\n",
        "# history = model.fit(\n",
        "#     datagen.flow(x_train, y_train, batch_size=32),\n",
        "#     steps_per_epoch=len(x_train) // 32,\n",
        "#     epochs=50,\n",
        "#     validation_data=(x_test, y_test),\n",
        "#     callbacks=callbacks\n",
        "# )\n",
        "\n",
        "# ===============================================\n",
        "\n",
        "print(\"âœ… Configure seu modelo e inicie o treinamento!\")\n",
        "\n",
        "# Passo 6: AvaliaÃ§Ã£o e AnÃ¡lise\n",
        "print(\"\\nğŸ“Š TEMPLATE PARA ANÃLISE DE RESULTADOS:\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "resultado_template = \"\"\"\n",
        "ğŸ¯ RESULTADOS FINAIS:\n",
        "   AcurÃ¡cia no teste: ____%\n",
        "   Tempo de treinamento: ____\n",
        "   Ã‰pocas necessÃ¡rias: ____\n",
        "\n",
        "ğŸ” ANÃLISE:\n",
        "   1. Overfitting observado? ____\n",
        "   2. Data augmentation ajudou? ____\n",
        "   3. Qual classe teve pior performance? ____\n",
        "   4. Principais desafios encontrados: ____\n",
        "\n",
        "ğŸš€ MELHORIAS PROPOSTAS:\n",
        "   1. ____________________\n",
        "   2. ____________________\n",
        "   3. ____________________\n",
        "\n",
        "ğŸ“ˆ COMPARAÃ‡ÃƒO COM FASHION MNIST:\n",
        "   Dificuldade: ____x maior\n",
        "   Tempo: ____x maior\n",
        "   Performance: ____% vs ____%\n",
        "\"\"\"\n",
        "\n",
        "print(resultado_template)\n",
        "\n",
        "print(\"\\nğŸ’¡ DICAS IMPORTANTES:\")\n",
        "print(\"   â€¢ CIFAR-10 requer mais Ã©pocas que Fashion MNIST\")\n",
        "print(\"   â€¢ Use GPU se disponÃ­vel para acelerar treinamento\")\n",
        "print(\"   â€¢ Monitore overfitting cuidadosamente\")\n",
        "print(\"   â€¢ Experimente diferentes learning rates\")\n",
        "print(\"   â€¢ Transfer learning pode ser uma alternativa\")\n",
        "\n",
        "print(\"\\nğŸ† META FINAL:\")\n",
        "print(\"   AlcanÃ§ar >80% acurÃ¡cia no CIFAR-10 com sua CNN!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de5cdb9a",
      "metadata": {},
      "source": [
        "## ğŸ“ ConclusÃµes e PrÃ³ximos Passos\n",
        "\n",
        "### âœ… O que aprendemos hoje:\n",
        "\n",
        "1. **Fundamentos**: OperaÃ§Ã£o de convoluÃ§Ã£o, pooling e arquitetura CNN\n",
        "2. **ImplementaÃ§Ã£o**: TensorFlow/Keras para construir CNNs\n",
        "3. **ComparaÃ§Ã£o**: CNNs vs MLPs tradicionais em termos de eficiÃªncia\n",
        "4. **AplicaÃ§Ã£o**: ClassificaÃ§Ã£o de imagens com Fashion MNIST\n",
        "5. **Arquiteturas histÃ³ricas**: LeNet-5 e sua importÃ¢ncia\n",
        "6. **Desafios prÃ¡ticos**: CIFAR-10 como prÃ³ximo passo\n",
        "\n",
        "### ğŸš€ PrÃ³ximos passos recomendados:\n",
        "\n",
        "1. **Arquiteturas modernas**: ResNet, VGG, EfficientNet\n",
        "2. **Transfer Learning**: Usar modelos prÃ©-treinados\n",
        "3. **TÃ©cnicas avanÃ§adas**: Data augmentation, batch normalization\n",
        "4. **AplicaÃ§Ãµes**: DetecÃ§Ã£o de objetos, segmentaÃ§Ã£o semÃ¢ntica\n",
        "5. **Vision Transformers**: Estado da arte atual\n",
        "\n",
        "### ğŸ“š Recursos para continuar aprendendo:\n",
        "\n",
        "- ğŸ“– **Livros**: \"Deep Learning\" (Goodfellow), \"Hands-On ML\" (GÃ©ron)\n",
        "- ğŸ“ **Cursos**: CS231n (Stanford), Fast.AI\n",
        "- ğŸ’» **PrÃ¡tica**: Kaggle competitions, Papers With Code\n",
        "- ğŸ† **Projetos**: Crie seu prÃ³prio classificador de imagens\n",
        "\n",
        "### ğŸ’¡ Dicas finais:\n",
        "\n",
        "1. **Comece simples**: LeNet-5 â†’ VGG â†’ ResNet â†’ Modernas\n",
        "2. **Entenda os dados**: EDA Ã© fundamental\n",
        "3. **Experimente**: Diferentes arquiteturas e hiperparÃ¢metros\n",
        "4. **Monitore**: Overfitting vs underfitting\n",
        "5. **Pratique**: Projetos reais consolidam o aprendizado\n",
        "\n",
        "---\n",
        "\n",
        "ğŸ‰ **ParabÃ©ns por completar este laboratÃ³rio!** \n",
        "\n",
        "VocÃª agora tem uma base sÃ³lida em CNNs. Continue explorando e construindo - o mundo da VisÃ£o Computacional estÃ¡ cheio de oportunidades fascinantes! ğŸŒŸ\n",
        "\n",
        "**Bons estudos e que a forÃ§a convolucional esteja com vocÃª!** ğŸ¤–âœ¨"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "8d68938bd6f1c8d824a292cb48fdc812f23ce0d2e12c844cec6ac89d2f668725"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
