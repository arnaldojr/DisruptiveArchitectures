{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arnaldojr/DisruptiveArchitectures/blob/master/material/aulas/batalharedes/batalha_das_redes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "423367be",
      "metadata": {
        "id": "423367be"
      },
      "source": [
        "## 2. Redes Neurais\n",
        "\n",
        "### Objetivos\n",
        "\n",
        "  - Conhecer e praticar Redes Neurais MLP\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09f7dea5",
      "metadata": {
        "id": "09f7dea5"
      },
      "source": [
        "## Batalha das redes \n",
        "\n",
        "Bem-vindos à nossa emocionante competição de Redes Neurais Multilayer Perceptron (MLP)! Hoje, vocês participarão de uma competição estilo Kaggle simplificada, projetada para colocar suas habilidades à prova e acelerar sua aprendizagem em um ambiente divertido e colaborativo.\n",
        "\n",
        "Ao longo desta aula, vocês enfrentarão três rodadas de desafios, cada uma com um dataset de dificuldade crescente. O objetivo é criar e otimizar modelos de redes neurais MLP para resolver problemas de classificação. Vocês trabalharão em duplas para desenvolver as melhores soluções possíveis, competindo uns contra os outros para ver quem alcança o melhor desempenho.\n",
        "\n",
        "A competição é estruturada da seguinte maneira:\n",
        "\n",
        " - Primeira rodada: Dataset fácil para que todos possam se familiarizar com o processo e começar a se aquecer.\n",
        " - Segunda rodada: Dataset de dificuldade média para desafiar suas habilidades e encorajá-los a explorar técnicas avançadas de otimização.\n",
        " - Terceira rodada: Dataset difícil, onde vocês colocarão à prova tudo o que aprenderam, desenvolvendo soluções para problemas complexos e realistas.\n",
        "  \n",
        "Vocês serão avaliados com base no desempenho de suas redes neurais e em critérios relacionados à arquitetura e complexidade da rede. Isso inclui métricas como acurácia, F1-Score e o número de neurônios usados no modelo. O objetivo é incentivar a criação de soluções eficientes e de alto desempenho.\n",
        "\n",
        "Preparem-se para mergulhar no mundo das redes neurais e aprender através da experiência prática. A competição será acirrada, mas, no final, todos sairão ganhando com o conhecimento e as habilidades adquiridas. \n",
        "\n",
        "\n",
        "Boa sorte a todos e que vença a melhor solução!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e34ea878",
      "metadata": {
        "id": "e34ea878"
      },
      "source": [
        "## Descrição dos Datasets para as Rodadas de Competição\n",
        "\n",
        "Ao longo desta competição, vocês enfrentarão três rodadas de desafios, cada uma com um dataset de dificuldade crescente. Abaixo estão as descrições dos datasets selecionados para cada rodada:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e1597c3",
      "metadata": {
        "id": "0e1597c3"
      },
      "source": [
        "### Primeira rodada - Dataset fácil: Iris Dataset\n",
        "\n",
        "O ``Iris dataset`` você já conhece, é um conjunto clássico de dados usado para problemas de classificação. Ele contém 150 amostras de flores de íris, divididas em 3 classes, cada uma representando um tipo de íris (Setosa, Versicolour e Virginica). Para cada amostra, há quatro características: comprimento e largura das sépalas e pétalas. \n",
        "\n",
        "O objetivo é criar um modelo MLP para classificar corretamente o tipo de íris com base nessas características.\n",
        "\n",
        "Para carregar o Iris dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "id": "002e8ee0",
      "metadata": {
        "id": "002e8ee0"
      },
      "outputs": [],
      "source": [
        "## importa dataset\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def iris():\n",
        "    iris = load_iris()\n",
        "    X, y = iris.data, iris.target\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f39c8fc4",
      "metadata": {
        "id": "f39c8fc4"
      },
      "source": [
        "### Segunda rodada - Dataset médio: Heart Disease UCI Dataset\n",
        "\n",
        "O ``Heart Disease UCI dataset`` é um conjunto de dados médicos que contém informações sobre pacientes e a presença de doenças cardíacas. São 303 amostras com 13 características, incluindo idade, sexo, pressão arterial em repouso e níveis de colesterol. \n",
        "\n",
        "O objetivo é classificar as amostras em duas classes: presença ou ausência de doença cardíaca.\n",
        "\n",
        "Para carregar o Heart Disease UCI dataset:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "id": "c2705065",
      "metadata": {
        "id": "c2705065"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def heart():\n",
        "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"\n",
        "    columns = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target']\n",
        "\n",
        "    heart_disease_data = pd.read_csv(url, header=None, names=columns, na_values=\"?\")\n",
        "    #valores ausentes (NaN), substitue pela média da coluna\n",
        "    heart_disease_data.fillna(heart_disease_data.mean(), inplace=True)  \n",
        "\n",
        "    X = heart_disease_data.drop('target', axis=1)\n",
        "    y = heart_disease_data[\"target\"].values\n",
        "    # Converta os valores de rótulo 1-4 em 1\n",
        "    y = np.where(y > 0, 1, 0)\n",
        "\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    \n",
        "    return X_train, X_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ab066f1",
      "metadata": {
        "id": "5ab066f1"
      },
      "source": [
        "### Terceira rodada - Dataset difícil: Cifar10 Dataset\n",
        "\n",
        "O ``cifar10`` é um conjunto de dados mais desafiador, contendo mais de 60.000 imagens em cores de 32x32 pixels, representando 10 classes de objetos capturados em imagens reais. \n",
        "\n",
        "\n",
        "link: [https://www.cs.toronto.edu/~kriz/cifar.html](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
        "\n",
        "O objetivo é criar um modelo MLP capaz de classificar corretamente cada imagem em seu respectivo dígito.\n",
        "\n",
        "Para carregar o SVHN dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "id": "16849a7a",
      "metadata": {
        "id": "16849a7a"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def cifar():\n",
        "    (X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "    X_train = X_train.astype('float32')\n",
        "    X_test = X_test.astype('float32')\n",
        "    #normaliza os dados para o pixel ficar com valores entre 0 e 1\n",
        "    X_train = X_train / 255.0\n",
        "    X_test = X_test / 255.0 \n",
        "\n",
        "    print('shape original')\n",
        "    print('X_train: {}, X_test: {}, y_train:{}, y_test:{}'.format(X_train.shape, X_test.shape, y_train.shape, y_test.shape))\n",
        "    print('shape redimensionado, flatten')\n",
        "    X_train = X_train.reshape(X_train.shape[0], -1)\n",
        "    X_test = X_test.reshape(X_test.shape[0], -1)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17ce46fe",
      "metadata": {
        "id": "17ce46fe"
      },
      "source": [
        "### Código base\n",
        "\n",
        "O seu objetivo é a criação da rede MLP mais eficiente, este coódigo base te auxilia no restante. \n",
        "\n",
        "Para rodar, execute as celulas de código abaixo e faça as alterações onde for solicitado:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "id": "b1f84da6",
      "metadata": {
        "id": "b1f84da6"
      },
      "outputs": [],
      "source": [
        "# Importação das bibliotecas necessárias\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.utils.np_utils import to_categorical  \n",
        "\n",
        "# importa as métricas de avaliação\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd2fa0c5",
      "metadata": {
        "id": "dd2fa0c5"
      },
      "source": [
        "### Primeiro passo\n",
        "\n",
        "Aqui você deve escolhar do dataset. \n",
        "\n",
        "Defina o dataset de acordo com rodada da competição.\n",
        "\n",
        " - dataset = 'rodada1'   --> primeira rodada\n",
        " - dataset = 'rodada2'   --> primeira rodada\n",
        " - dataset = 'rodada3'   --> primeira rodada\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04c9d306",
      "metadata": {
        "id": "04c9d306"
      },
      "outputs": [],
      "source": [
        "### dataset da rodada, basta descomentar uma das linhas abaixo\n",
        "\n",
        "#dataset = 'rodada1'\n",
        "#dataset = 'rodada2'\n",
        "dataset = 'rodada3'\n",
        "\n",
        "\n",
        "\n",
        "# Função para carregar e preprocessar o dataset\n",
        "def load_and_preprocess_data(dataset):\n",
        "    if dataset == \"rodada1\":\n",
        "        X_train, X_test, y_train, y_test = iris()\n",
        "        \n",
        "    elif dataset == \"rodada2\":\n",
        "        X_train, X_test, y_train, y_test = heart()\n",
        "        \n",
        "    else:\n",
        "        X_train, X_test, y_train, y_test = cifar()\n",
        "    \n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# Carregue e preprocess os dados\n",
        "X_train, X_test, y_train, y_test = load_and_preprocess_data(dataset)\n",
        "\n",
        "print(\"\\n---------LEIA COM ATENÇÃO--------------------------\")\n",
        "print('\\nX_train: {}, X_test: {}\\ny_train: {}, y_test: {}'.format(X_train.shape, X_test.shape, y_train.shape, y_test.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66dab7ca",
      "metadata": {
        "id": "66dab7ca"
      },
      "source": [
        "### Segundo passo\n",
        "\n",
        "Crie sua rede neural MLP dentro da função create_model().\n",
        "\n",
        "É aqui que você vai trabalhar! Use a função create_model() para definir a arquitetura da sua rede neural MLP.\n",
        "\n",
        "\n",
        "### Dicas\n",
        "\n",
        "- Adicione as camadas Densas, Dropout, etc.\n",
        "- Adicione/altere quantidade de neuronios.\n",
        "- Adicione/altere função de ativação ('relu','softmax','sigmoid')\n",
        "\n",
        "Exemplos:\n",
        "* model.add(Dense(18, activation='relu', input_shape=(4,)))\n",
        "* model.add(Dropout(rate=0.5))\n",
        "* model.add(BatchNormalization())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2c0fe00",
      "metadata": {
        "id": "b2c0fe00"
      },
      "outputs": [],
      "source": [
        "# Função para criar o modelo MLP\n",
        "def create_model(dataset):\n",
        "    model = Sequential()\n",
        "    # Adicione as camadas aqui\n",
        "    \n",
        "\n",
        "  \n",
        "\n",
        " \n",
        "    # Compile o modelo Não altera aqui, por enquanto.\n",
        "    if dataset == 'rodada2': model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    else: model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Crie o modelo\n",
        "print(dataset)\n",
        "model = create_model(dataset)\n",
        "\n",
        "model.summary()\n",
        "print(\"Loss function:\", model.loss)\n",
        "print(\"Optimizer name:\", model.optimizer.get_config()[\"name\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "862d844c",
      "metadata": {
        "id": "862d844c"
      },
      "source": [
        "### Terceiro passo\n",
        "\n",
        "Treine o seu modelo, aqui voce deve trabalhar para definir os parametros de treinamento da rede neural.\n",
        "\n",
        "### Dicas\n",
        "\n",
        "- Altere quantidade de epocas, batch_size e validation_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ab92b49",
      "metadata": {
        "id": "1ab92b49"
      },
      "outputs": [],
      "source": [
        "# Treine o modelo\n",
        "history = model.fit(X_train, y_train, epochs=10, validation_split=0.2)\n",
        "\n",
        "#Validadção\n",
        "train_loss, train_acc = model.evaluate(X_train,  y_train, verbose=2)\n",
        "test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "614ed279",
      "metadata": {
        "id": "614ed279"
      },
      "source": [
        "### Quarto passo\n",
        "\n",
        "Avaliação do modelo treinado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e42fe69",
      "metadata": {
        "id": "8e42fe69"
      },
      "outputs": [],
      "source": [
        "## exibe os graficos da função loss e acuracia\n",
        "\n",
        "history_df = pd.DataFrame(history.history)\n",
        "\n",
        "history_df[['loss','val_loss']].plot();\n",
        "history_df[['accuracy','val_accuracy']].plot();\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ef95ee8",
      "metadata": {
        "id": "7ef95ee8"
      },
      "outputs": [],
      "source": [
        "# Função para avaliar o modelo\n",
        "def train_and_evaluate_model(model, dataset, X_train, X_test, y_train, y_test):\n",
        "\n",
        "    # Faça previsões no conjunto de teste\n",
        "    if dataset =='rodada2':\n",
        "      y_pred = np.round(model.predict(X_test))\n",
        "    else:\n",
        "      y_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "    \n",
        "    # Converta os rótulos para inteiros\n",
        "    y_test = y_test.astype(int)\n",
        "    y_pred = y_pred.astype(int)\n",
        "\n",
        "    \n",
        "    # Calcule as métricas de avaliação\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    \n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# Treine e avalie o modelo\n",
        "accuracy, precision, recall, f1 = train_and_evaluate_model(model,dataset, X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Exiba os resultados\n",
        "print(\"Acurácia:\", accuracy)\n",
        "print(\"Precisão:\", precision)\n",
        "print(\"Revocação:\", recall)\n",
        "print(\"F1-Score:\", f1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pontuação\n",
        "\n",
        "Para computar seus pontos anote os resultados obtidos \n",
        "\n",
        " - Acurácia\n",
        " - Quantidade de camadas \n",
        " \n",
        "## se der empate\n",
        "\n",
        " - F1-Scores\n",
        " - Quantidade de parametros treináveis \n",
        "\n"
      ],
      "metadata": {
        "id": "8kp_bndvWqOw"
      },
      "id": "8kp_bndvWqOw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94f2fb40",
      "metadata": {
        "id": "94f2fb40"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9e8ebf0",
      "metadata": {
        "id": "f9e8ebf0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}