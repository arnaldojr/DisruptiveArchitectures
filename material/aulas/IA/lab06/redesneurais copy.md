# Redes Neurais Artificiais: Guia Completo

## Sum√°rio
1. [Introdu√ß√£o](#introdu√ß√£o)
2. [Fundamentos Biol√≥gicos](#fundamentos-biol√≥gicos)
3. [Neur√¥nio Artificial](#neur√¥nio-artificial)
4. [Perceptron](#perceptron)
5. [Multilayer Perceptron (MLP)](#multilayer-perceptron-mlp)
6. [Algoritmos de Treinamento](#algoritmos-de-treinamento)
7. [Fun√ß√µes de Ativa√ß√£o](#fun√ß√µes-de-ativa√ß√£o)
8. [Regulariza√ß√£o e Otimiza√ß√£o](#regulariza√ß√£o-e-otimiza√ß√£o)
9. [Aplica√ß√µes Pr√°ticas](#aplica√ß√µes-pr√°ticas)
10. [Exerc√≠cios e Projetos](#exerc√≠cios-e-projetos)

## Introdu√ß√£o

As **Redes Neurais Artificiais (RNA)** s√£o modelos computacionais inspirados no funcionamento do sistema nervoso biol√≥gico. Elas representam uma das abordagens mais poderosas e vers√°teis do aprendizado de m√°quina, capazes de:

- **Aprender padr√µes complexos** em dados
- **Aproximar fun√ß√µes n√£o-lineares** arbitr√°rias
- **Resolver problemas** de classifica√ß√£o, regress√£o e clustering
- **Processar diferentes tipos** de dados (imagens, texto, s√©ries temporais)

### Por que estudar Redes Neurais?

1. **Versatilidade**: Aplicam-se a diversos dom√≠nios
2. **Poder expressivo**: Podem modelar rela√ß√µes complexas
3. **Evolu√ß√£o cont√≠nua**: Base para Deep Learning e IA moderna
4. **Resultados pr√°ticos**: Solucionam problemas reais

## Fundamentos Biol√≥gicos

### O Neur√¥nio Biol√≥gico

O neur√¥nio √© a unidade fundamental do sistema nervoso, composto por:

![alt text](Complete_neuron_cell_diagram_en.svg)


```
Dendritos ‚Üí Soma ‚Üí Ax√¥nio ‚Üí Sinapses
    ‚Üë        ‚Üë       ‚Üë        ‚Üë
  Entrada  Processamento  Transmiss√£o  Sa√≠da
```

#### Componentes principais:

- **Dendritos**: Recebem sinais de outros neur√¥nios
- **Soma (corpo celular)**: Integra e processa os sinais
- **Ax√¥nio**: Transmite o sinal processado
- **Sinapses**: Conex√µes com outros neur√¥nios

### Processo de Comunica√ß√£o Neural

1. **Recep√ß√£o**: Dendritos captam neurotransmissores
2. **Integra√ß√£o**: Soma pondera e combina os sinais
3. **Limiar**: Se o potencial excede um limiar, o neur√¥nio "dispara"
4. **Transmiss√£o**: Sinal el√©trico percorre o ax√¥nio
5. **Libera√ß√£o**: Neurotransmissores s√£o liberados nas sinapses

## Neur√¥nio Artificial

### Modelo Matem√°tico

O neur√¥nio artificial √© uma abstra√ß√£o matem√°tica do neur√¥nio biol√≥gico:

![alt text](image.png)

```
x‚ÇÅ ‚îÄ‚îÄw‚ÇÅ‚îÄ‚îÄ‚îê
x‚ÇÇ ‚îÄ‚îÄw‚ÇÇ‚îÄ‚îÄ‚î§
    ...  ‚îú‚îÄ‚Üí Œ£ ‚îÄ‚îÄ‚Üí f(net) ‚îÄ‚îÄ‚Üí y
x‚Çô ‚îÄ‚îÄw‚Çô‚îÄ‚îÄ‚îò
    b ‚îÄ‚îÄ‚îÄ‚îò
```

#### Equa√ß√µes fundamentais:

**Net Input (Entrada l√≠quida):**
```
net = Œ£(w·µ¢ √ó x·µ¢) + b = w‚ÇÅx‚ÇÅ + w‚ÇÇx‚ÇÇ + ... + w‚Çôx‚Çô + b
```

**Sa√≠da:**
```
y = f(net)
```

Onde:
- `x·µ¢`: Entradas do neur√¥nio
- `w·µ¢`: Pesos sin√°pticos
- `b`: Bias (limiar)
- `f`: Fun√ß√£o de ativa√ß√£o
- `y`: Sa√≠da do neur√¥nio

### Fun√ß√µes de Ativa√ß√£o Cl√°ssicas

#### 1. Fun√ß√£o Degrau (Step Function)
```
f(x) = { 1, se x ‚â• 0
       { 0, se x < 0
```
- **Uso**: Perceptron cl√°ssico
- **Caracter√≠stica**: Sa√≠da bin√°ria

#### 2. Fun√ß√£o Sigm√≥ide
```
f(x) = 1 / (1 + e^(-x))
```
- **Intervalo**: (0, 1)
- **Caracter√≠stica**: Diferenci√°vel, suave
- **Problema**: Satura√ß√£o dos gradientes

#### 3. Fun√ß√£o Tangente Hiperb√≥lica (tanh)
```
f(x) = (e^x - e^(-x)) / (e^x + e^(-x))
```
- **Intervalo**: (-1, 1)
- **Vantagem**: Centrada em zero

#### 4. Fun√ß√£o ReLU (Rectified Linear Unit)
```
f(x) = max(0, x)
```
- **Vantagem**: Resolve o problema de gradientes
- **Uso**: Redes profundas modernas

## Perceptron

### Conceito e Hist√≥ria

O **Perceptron**, desenvolvido por Frank Rosenblatt em 1957, foi o primeiro algoritmo de aprendizado para redes neurais que garantia converg√™ncia para problemas linearmente separ√°veis.

### Arquitetura do Perceptron

```
Entrada ‚Üí Pesos ‚Üí Soma ‚Üí Ativa√ß√£o ‚Üí Sa√≠da
x‚ÇÅ,x‚ÇÇ,...,x‚Çô ‚Üí w‚ÇÅ,w‚ÇÇ,...,w‚Çô ‚Üí Œ£ ‚Üí f ‚Üí y
```

### Algoritmo de Treinamento

**Pseudoc√≥digo:**
```
1. Inicializar pesos aleatoriamente
2. Para cada √©poca:
   a. Para cada amostra (x, d):
      - Calcular sa√≠da: y = f(Œ£w·µ¢x·µ¢ + b)
      - Calcular erro: e = d - y
      - Atualizar pesos: w·µ¢ = w·µ¢ + Œ∑ √ó e √ó x·µ¢
      - Atualizar bias: b = b + Œ∑ √ó e
3. Repetir at√© converg√™ncia
```

**Par√¢metros:**
- `Œ∑` (eta): Taxa de aprendizado
- `d`: Sa√≠da desejada
- `e`: Erro

### Teorema da Converg√™ncia

**Teorema**: Se os dados s√£o linearmente separ√°veis, o algoritmo Perceptron converge em um n√∫mero finito de itera√ß√µes.

### Limita√ß√µes do Perceptron

1. **Separabilidade linear**: S√≥ resolve problemas linearmente separ√°veis
2. **Problema XOR**: N√£o consegue resolver o XOR
3. **Fun√ß√£o de ativa√ß√£o**: Limitado a fun√ß√µes lineares por partes

## Multilayer Perceptron (MLP)

### Superando as Limita√ß√µes

O **MLP** resolve as limita√ß√µes do Perceptron atrav√©s de:

1. **Camadas ocultas**: Permitem n√£o-linearidade
2. **M√∫ltiplas camadas**: Aumentam poder expressivo
3. **Backpropagation**: Algoritmo de treinamento eficiente

### Arquitetura MLP

![alt text](image-1.png)

```
Camada de    Camada(s)      Camada de
Entrada   ‚Üí   Oculta(s)   ‚Üí   Sa√≠da

x‚ÇÅ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   h‚ÇÅ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   y‚ÇÅ
x‚ÇÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§   h‚ÇÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§   y‚ÇÇ
  ...    ‚îú‚îÄ‚Üí  ... ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§‚Üí  ...
x‚Çô ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   h‚Çò ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   y‚Çñ
```

### Teorema da Aproxima√ß√£o Universal

**Teorema**: Uma rede neural com uma √∫nica camada oculta e um n√∫mero suficiente de neur√¥nios pode aproximar qualquer fun√ß√£o cont√≠nua com precis√£o arbitr√°ria.

### Regras Pr√°ticas para Arquitetura

Historicamente, quando redes neurais eram menores e o custo computacional mais alto, surgiram algumas **heur√≠sticas** para estimar o tamanho inicial da camada oculta em redes totalmente conectadas (MLPs).  
Essas regras **n√£o s√£o leis fixas**, mas podem servir como **ponto de partida**:

#### N√∫mero de neur√¥nios na camada oculta:

- 1. Regra dos 2/3:
$$
\text{neur√¥nios ocultos} \approx \frac{2}{3} \times (\text{neur√¥nios de entrada}) + \text{neur√¥nios de sa√≠da}
$$

> **Ideia:** reduzir a dimensionalidade da entrada mantendo espa√ßo para representar as sa√≠das.

- 2. M√©dia geom√©trica

$$
\text{neur√¥nios ocultos} \approx \sqrt{\text{entradas} \times \text{sa√≠das}}
$$

> **Ideia:** buscar um equil√≠brio proporcional entre o tamanho da entrada e o tamanho da sa√≠da.

---

- 3. Experimenta√ß√£o incremental *(abordagem mais usada atualmente)*

    - Comece com uma rede pequena.  
    - Monitore as m√©tricas de treinamento e valida√ß√£o.  
    - Aumente gradualmente a quantidade de neur√¥nios at√© atingir bom desempenho sem sobreajuste (*overfitting*).  
    - Utilize t√©cnicas de regulariza√ß√£o (*dropout*, L2, *batch normalization*) para manter a generaliza√ß√£o.


!!! tip

    > Essas regras n√£o consideram fatores como complexidade do problema, qualidade dos dados ou arquiteturas modernas (CNNs, RNNs, Transformers). 

    > Hoje, a pr√°tica recomendada √© combinar um **chute inicial** com **ajuste via valida√ß√£o cruzada** e ferramentas de **busca de hiperpar√¢metros**.


#### N√∫mero de camadas ocultas:

O n√∫mero de camadas ocultas em uma rede neural influencia diretamente a **capacidade de representa√ß√£o** do modelo.  
De forma geral, temos:

- **1 camada oculta:**  
  Indicada para problemas que se tornam linearmente separ√°veis ap√≥s uma transforma√ß√£o n√£o linear.  
  Exemplo: classifica√ß√£o simples com fronteiras suaves.

- **2 camadas ocultas:**  
  Capaz de aproximar **qualquer fun√ß√£o cont√≠nua** arbitr√°ria (Teorema da Aproxima√ß√£o Universal).  
  √ötil quando h√° rela√ß√µes mais complexas entre entrada e sa√≠da.

- **3 ou mais camadas ocultas:**  
  Necess√°rias para representar **fun√ß√µes descont√≠nuas** ou padr√µes muito complexos.  
  Base do **Deep Learning**, permitindo a extra√ß√£o de caracter√≠sticas em m√∫ltiplos n√≠veis.

> üí° **Observa√ß√£o:** Embora mais camadas aumentem a capacidade do modelo, tamb√©m elevam o risco de **overfitting** e a necessidade de mais dados e regulariza√ß√£o.



## Algoritmos de Treinamento

### Backpropagation

O **algoritmo de retropropaga√ß√£o** √© o m√©todo padr√£o para treinar MLPs.

#### Fases do Algoritmo:

**1. Forward Pass (Propaga√ß√£o Direta):**
```python
# Para cada camada l
for l in range(1, L):
    z[l] = W[l] @ a[l-1] + b[l]  # Linear combination
    a[l] = activation(z[l])       # Activation function
```

**2. Backward Pass (Retropropaga√ß√£o):**
```python
# Calcular erro da sa√≠da
delta[L] = (a[L] - y) * activation_derivative(z[L])

# Propagar erro para tr√°s
for l in range(L-1, 0, -1):
    delta[l] = (W[l+1].T @ delta[l+1]) * activation_derivative(z[l])
```

**3. Atualiza√ß√£o dos Pesos:**
```python
# Para cada camada
for l in range(1, L):
    W[l] -= learning_rate * (delta[l] @ a[l-1].T)
    b[l] -= learning_rate * delta[l]
```

### Varia√ß√µes do Gradient Descent

#### 1. Batch Gradient Descent
- **Caracter√≠stica**: Usa todo o dataset por itera√ß√£o
- **Vantagem**: Converg√™ncia est√°vel
- **Desvantagem**: Lento para grandes datasets

#### 2. Stochastic Gradient Descent (SGD)
- **Caracter√≠stica**: Uma amostra por vez
- **Vantagem**: R√°pido, pode escapar de m√≠nimos locais
- **Desvantagem**: Converg√™ncia ruidosa

#### 3. Mini-batch Gradient Descent
- **Caracter√≠stica**: Pequenos grupos de amostras
- **Vantagem**: Balanceia velocidade e estabilidade
- **Uso**: Mais comum na pr√°tica

## Fun√ß√µes de Ativa√ß√£o Modernas

### ReLU e Varia√ß√µes

#### ReLU (Rectified Linear Unit)
```python
def relu(x):
    return np.maximum(0, x)
```
**Vantagens:**
- Computacionalmente eficiente
- Resolve gradientes que desvanecem
- Induz esparsidade

**Desvantagens:**
- Neur√¥nios podem "morrer"
- N√£o diferenci√°vel em zero

#### Leaky ReLU
```python
def leaky_relu(x, alpha=0.01):
    return np.where(x > 0, x, alpha * x)
```
**Vantagem:** Evita neur√¥nios mortos

#### ELU (Exponential Linear Unit)
```python
def elu(x, alpha=1.0):
    return np.where(x > 0, x, alpha * (np.exp(x) - 1))
```
**Vantagem:** Suave em toda parte

### Fun√ß√µes de Ativa√ß√£o para Sa√≠da

#### Softmax (Classifica√ß√£o Multiclasse)
```python
def softmax(x):
    exp_x = np.exp(x - np.max(x))
    return exp_x / np.sum(exp_x)
```

#### Linear (Regress√£o)
```python
def linear(x):
    return x
```

## Regulariza√ß√£o e Otimiza√ß√£o

### T√©cnicas de Regulariza√ß√£o

#### 1. L1 Regularization (Lasso)
```
Loss = MSE + Œª‚ÇÅ √ó Œ£|w·µ¢|
```
- **Efeito**: Induz esparsidade

#### 2. L2 Regularization (Ridge)
```
Loss = MSE + Œª‚ÇÇ √ó Œ£w·µ¢¬≤
```
- **Efeito**: Reduz magnitude dos pesos

#### 3. Dropout
- **Mecanismo**: Desativa neur√¥nios aleatoriamente durante treinamento
- **Vantagem**: Reduz overfitting

#### 4. Early Stopping
- **Mecanismo**: Para treinamento quando valida√ß√£o para de melhorar
- **Implementa√ß√£o**: Monitora loss de valida√ß√£o

### Otimizadores Avan√ßados

#### Adam (Adaptive Moment Estimation)
```python
# Par√¢metros adaptativos
m = Œ≤‚ÇÅ √ó m + (1 - Œ≤‚ÇÅ) √ó gradient
v = Œ≤‚ÇÇ √ó v + (1 - Œ≤‚ÇÇ) √ó gradient¬≤

# Corre√ß√£o de vi√©s
m_hat = m / (1 - Œ≤‚ÇÅ·µó)
v_hat = v / (1 - Œ≤‚ÇÇ·µó)

# Atualiza√ß√£o
weights -= learning_rate √ó m_hat / (‚àöv_hat + Œµ)
```
