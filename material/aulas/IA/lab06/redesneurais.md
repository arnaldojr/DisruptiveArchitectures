# Redes Neurais Artificiais

## IntroduÃ§Ã£o

As **Redes Neurais Artificiais (RNA)** sÃ£o modelos computacionais inspirados no funcionamento do sistema nervoso biolÃ³gico. Elas representam uma das abordagens mais poderosas e versÃ¡teis do aprendizado de mÃ¡quina, capazes de:

- **Aprender padrÃµes nÃ£o lineares** e interaÃ§Ãµes entre variÃ¡veis difÃ­ceis de modelar com tÃ©cnicas lineares
- **Aproximar funÃ§Ãµes nÃ£o-lineares** arbitrÃ¡rias (quando bem dimensionadas e treinadas), graÃ§as ao seu poder de representaÃ§Ã£o
- **Resolver problemas** de classificaÃ§Ã£o, regressÃ£o e clustering
- **Processar mÃºltiplas modalidades:** como dados de dados de imagens, texto e sÃ©ries temporais...

### Quando considerar RNAs (regra prÃ¡tica):

- RelaÃ§Ãµes claramente "nÃ£o lineares" entre entradas e saÃ­das.
- "Muitos atributos" (alta dimensionalidade) e grande volume de dados.
- Necessidade de aprender representaÃ§Ãµes (extraÃ§Ã£o automÃ¡tica de caracterÃ­sticas).

### Quando suspeitar que RNAs nÃ£o sÃ£o a melhor 1Âª escolha:

 - Poucos dados rotulados e problema simples â†’ tente modelos lineares, kNN ou Ã¡rvores antes.
 - Forte necessidade de interpretabilidade imediata â†’ prefira modelos explicÃ¡veis (Ã¡rvores, regressÃµes com regularizaÃ§Ã£o, regras).

## IntuiÃ§Ã£o bÃ¡sica

### O NeurÃ´nio BiolÃ³gico

O neurÃ´nio Ã© a unidade fundamental do sistema nervoso, composto por:

![alt text](Complete_neuron_cell_diagram_en.svg)


```
Dendritos â†’ Soma â†’ AxÃ´nio â†’ Sinapses
    â†‘        â†‘       â†‘        â†‘
  Entrada  Processamento  TransmissÃ£o  SaÃ­da
```

#### Componentes principais:

- **Dendritos**: Recebem sinais de outros neurÃ´nios
- **Soma (corpo celular)**: Integra e processa os sinais
- **AxÃ´nio**: Transmite o sinal processado
- **Sinapses**: ConexÃµes com outros neurÃ´nios

### Processo de ComunicaÃ§Ã£o Neural

1. **RecepÃ§Ã£o**: Dendritos captam neurotransmissores
2. **IntegraÃ§Ã£o**: Soma pondera e combina os sinais
3. **Limiar**: Se o potencial excede um limiar, o neurÃ´nio "dispara"
4. **TransmissÃ£o**: Sinal elÃ©trico percorre o axÃ´nio
5. **LiberaÃ§Ã£o**: Neurotransmissores sÃ£o liberados nas sinapses

## NeurÃ´nio Artificial

### Modelo MatemÃ¡tico

O neurÃ´nio artificial Ã© uma abstraÃ§Ã£o matemÃ¡tica do neurÃ´nio biolÃ³gico:

![alt text](image.png)

```
xâ‚ â”€â”€wâ‚â”€â”€â”
xâ‚‚ â”€â”€wâ‚‚â”€â”€â”¤
    ...  â”œâ”€â†’ Î£ â”€â”€â†’ f(net) â”€â”€â†’ y
xâ‚™ â”€â”€wâ‚™â”€â”€â”˜
    b â”€â”€â”€â”˜
```

#### EquaÃ§Ãµes fundamentais:

**Net Input (Entrada lÃ­quida):**
```
net = Î£(wáµ¢ Ã— xáµ¢) + b = wâ‚xâ‚ + wâ‚‚xâ‚‚ + ... + wâ‚™xâ‚™ + b
```

**SaÃ­da:**
```
y = f(net)
```

Onde:
- `xáµ¢`: Entradas do neurÃ´nio
- `wáµ¢`: Pesos sinÃ¡pticos
- `b`: Bias (limiar)
- `f`: FunÃ§Ã£o de ativaÃ§Ã£o
- `y`: SaÃ­da do neurÃ´nio

### FunÃ§Ãµes de AtivaÃ§Ã£o ClÃ¡ssicas

#### 1. FunÃ§Ã£o Degrau (Step Function)
```
f(x) = { 1, se x â‰¥ 0
       { 0, se x < 0
```
- **Uso**: Perceptron clÃ¡ssico
- **CaracterÃ­stica**: SaÃ­da binÃ¡ria

#### 2. FunÃ§Ã£o SigmÃ³ide
```
f(x) = 1 / (1 + e^(-x))
```
- **Intervalo**: (0, 1)
- **CaracterÃ­stica**: DiferenciÃ¡vel, suave
- **Problema**: SaturaÃ§Ã£o dos gradientes

#### 3. FunÃ§Ã£o Tangente HiperbÃ³lica (tanh)
```
f(x) = (e^x - e^(-x)) / (e^x + e^(-x))
```
- **Intervalo**: (-1, 1)
- **Vantagem**: Centrada em zero

#### 4. FunÃ§Ã£o ReLU (Rectified Linear Unit)
```
f(x) = max(0, x)
```
- **Vantagem**: Resolve o problema de gradientes
- **Uso**: Redes profundas modernas

## Perceptron

### Conceito e HistÃ³ria

O **Perceptron**, desenvolvido por Frank Rosenblatt em 1957, foi o primeiro algoritmo de aprendizado para redes neurais que garantia convergÃªncia para problemas linearmente separÃ¡veis.

### Arquitetura do Perceptron

```
Entrada â†’ Pesos â†’ Soma â†’ AtivaÃ§Ã£o â†’ SaÃ­da
xâ‚,xâ‚‚,...,xâ‚™ â†’ wâ‚,wâ‚‚,...,wâ‚™ â†’ Î£ â†’ f â†’ y
```

### Algoritmo de Treinamento

**PseudocÃ³digo:**
```
1. Inicializar pesos aleatoriamente
2. Para cada Ã©poca:
   a. Para cada amostra (x, d):
      - Calcular saÃ­da: y = f(Î£wáµ¢xáµ¢ + b)
      - Calcular erro: e = d - y
      - Atualizar pesos: wáµ¢ = wáµ¢ + Î· Ã— e Ã— xáµ¢
      - Atualizar bias: b = b + Î· Ã— e
3. Repetir atÃ© convergÃªncia
```

**ParÃ¢metros:**
- `Î·` (eta): Taxa de aprendizado
- `d`: SaÃ­da desejada
- `e`: Erro

### Teorema da ConvergÃªncia

**Teorema**: Se os dados sÃ£o linearmente separÃ¡veis, o algoritmo Perceptron converge em um nÃºmero finito de iteraÃ§Ãµes.

### LimitaÃ§Ãµes do Perceptron

1. **Separabilidade linear**: SÃ³ resolve problemas linearmente separÃ¡veis
2. **Problema XOR**: NÃ£o consegue resolver o XOR
3. **FunÃ§Ã£o de ativaÃ§Ã£o**: Limitado a funÃ§Ãµes lineares por partes

## Multilayer Perceptron (MLP)

### Superando as LimitaÃ§Ãµes

O **MLP** resolve as limitaÃ§Ãµes do Perceptron atravÃ©s de:

1. **Camadas ocultas**: Permitem nÃ£o-linearidade
2. **MÃºltiplas camadas**: Aumentam poder expressivo
3. **Backpropagation**: Algoritmo de treinamento eficiente

### Arquitetura MLP

![alt text](image-1.png)

```
Camada de    Camada(s)      Camada de
Entrada   â†’   Oculta(s)   â†’   SaÃ­da

xâ‚ â”€â”€â”€â”€â”€â”€â”   hâ‚ â”€â”€â”€â”€â”€â”€â”€â”€â”   yâ‚
xâ‚‚ â”€â”€â”€â”€â”€â”€â”¤   hâ‚‚ â”€â”€â”€â”€â”€â”€â”€â”€â”¤   yâ‚‚
  ...    â”œâ”€â†’  ... â”€â”€â”€â”€â”€â”€â”€â”€â”¤â†’  ...
xâ‚™ â”€â”€â”€â”€â”€â”€â”˜   hâ‚˜ â”€â”€â”€â”€â”€â”€â”€â”€â”˜   yâ‚–
```

### Teorema da AproximaÃ§Ã£o Universal

**Teorema**: Uma rede neural com uma Ãºnica camada oculta e um nÃºmero suficiente de neurÃ´nios pode aproximar qualquer funÃ§Ã£o contÃ­nua com precisÃ£o arbitrÃ¡ria.

### Regras PrÃ¡ticas para Arquitetura

Historicamente, quando redes neurais eram menores e o custo computacional mais alto, surgiram algumas **heurÃ­sticas** para estimar o tamanho inicial da camada oculta em redes totalmente conectadas (MLPs).  
Essas regras **nÃ£o sÃ£o leis fixas**, mas podem servir como **ponto de partida**:

#### NÃºmero de neurÃ´nios na camada oculta:

- 1. Regra dos 2/3:
$$
\text{neurÃ´nios ocultos} \approx \frac{2}{3} \times (\text{neurÃ´nios de entrada}) + \text{neurÃ´nios de saÃ­da}
$$

> **Ideia:** reduzir a dimensionalidade da entrada mantendo espaÃ§o para representar as saÃ­das.

- 2. MÃ©dia geomÃ©trica

$$
\text{neurÃ´nios ocultos} \approx \sqrt{\text{entradas} \times \text{saÃ­das}}
$$

> **Ideia:** buscar um equilÃ­brio proporcional entre o tamanho da entrada e o tamanho da saÃ­da.

---

- 3. ExperimentaÃ§Ã£o incremental *(abordagem mais usada atualmente)*

    - Comece com uma rede pequena.  
    - Monitore as mÃ©tricas de treinamento e validaÃ§Ã£o.  
    - Aumente gradualmente a quantidade de neurÃ´nios atÃ© atingir bom desempenho sem sobreajuste (*overfitting*).  
    - Utilize tÃ©cnicas de regularizaÃ§Ã£o (*dropout*, L2, *batch normalization*) para manter a generalizaÃ§Ã£o.


!!! tip

    > Essas regras nÃ£o consideram fatores como complexidade do problema, qualidade dos dados ou arquiteturas modernas (CNNs, RNNs, Transformers). 

    > Hoje, a prÃ¡tica recomendada Ã© combinar um **chute inicial** com **ajuste via validaÃ§Ã£o cruzada** e ferramentas de **busca de hiperparÃ¢metros**.


#### NÃºmero de camadas ocultas:

O nÃºmero de camadas ocultas em uma rede neural influencia diretamente a **capacidade de representaÃ§Ã£o** do modelo.  
De forma geral, temos:

- **1 camada oculta:**  
  Indicada para problemas que se tornam linearmente separÃ¡veis apÃ³s uma transformaÃ§Ã£o nÃ£o linear.  
  Exemplo: classificaÃ§Ã£o simples com fronteiras suaves.

- **2 camadas ocultas:**  
  Capaz de aproximar **qualquer funÃ§Ã£o contÃ­nua** arbitrÃ¡ria (Teorema da AproximaÃ§Ã£o Universal).  
  Ãštil quando hÃ¡ relaÃ§Ãµes mais complexas entre entrada e saÃ­da.

- **3 ou mais camadas ocultas:**  
  NecessÃ¡rias para representar **funÃ§Ãµes descontÃ­nuas** ou padrÃµes muito complexos.  
  Base do **Deep Learning**, permitindo a extraÃ§Ã£o de caracterÃ­sticas em mÃºltiplos nÃ­veis.

> ğŸ’¡ **ObservaÃ§Ã£o:** Embora mais camadas aumentem a capacidade do modelo, tambÃ©m elevam o risco de **overfitting** e a necessidade de mais dados e regularizaÃ§Ã£o.


