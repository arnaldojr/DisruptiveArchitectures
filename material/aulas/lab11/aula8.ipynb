{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Aprendizagem de máquina\n",
    "\n",
    "### Objetivos\n",
    "\n",
    "  - Praticar os algoritmos de aprendizado de maquina\n",
    "  - Conhecer e aplicar o algoritmo Naive Bayes\n",
    "  \n",
    "### Objetivos específicos\n",
    "\n",
    "   - Obter ao final da aula de hoje um roteiro com dicas de como processar algoritmos de aprendizado de maquina."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dinamica da aula\n",
    "\n",
    "    - 10min - Apresentação do notebook e do case a ser resolvido. \n",
    "    - 30min - Desenvolvimento do grupo para resolver o notebook\n",
    "    - 60min - Resolução em conjunto (aluno + professor) do problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projeto completo de aprendizado de máquina\n",
    "\n",
    "O objetivo deste notebook é servir como inspiração para realizar uma análise exploratória de dados e desenvolimento de modelos preditivos usando ML. \n",
    "\n",
    "\n",
    "\n",
    "De forma geral, e bem superficial, podemos separar esse processo em algumas etapa:\n",
    "\n",
    "    [ ] Análise exploratória e preparação dos dados \n",
    "    [ ] Treina um(uns) modelo(s) de ML\n",
    "    [ ] Análisa e valida o modelo, responde as perguntas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificador de renda \n",
    "\n",
    "Você foi contratado por uma empresa para prestar um serviço de consultor, nesse sentido a empresa disponibilizou uma base de dados dos seus clientes e gostaria de saber se é possível criar um modelo preditivo que deve classificar se determinadas pessoas ganham mais ou menos de 50k por ano. \n",
    "\n",
    "\n",
    "Nosso dataset:http://archive.ics.uci.edu/ml/datasets/Adult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importa as bibliotecas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd # data frame\n",
    "import numpy as np # matriz\n",
    "import matplotlib.pyplot as plt # grafico\n",
    "import seaborn as sns # graficos estatisticos\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carrega o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('df.csv', header = None)\n",
    "\n",
    "columns_name = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', 'relationship',\n",
    "             'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'income']\n",
    "\n",
    "df.columns = columns_name\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descrição do dataset:\n",
    "\n",
    "    Age – idade \n",
    "    Workclass – classe de trabalho\n",
    "    fnlwgt – número de pessoas que amostra representa comparada a população.\n",
    "    Education – educação\n",
    "    Education_Num – anos de escolaridade\n",
    "    Martial_Status – Estado Civil\n",
    "    Occupation – ocupação, cargo que ocupa\n",
    "    Relationship – parentesco\n",
    "    Race – raça\n",
    "    Sex – sexo\n",
    "    Capital_Gain – ganho capital\n",
    "    Capital_Loss – perda capital\n",
    "    Hours_per_week – horas por semana\n",
    "    Country – Nacionalidade\n",
    "    \n",
    "    income – renda anual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## verifica as informações do dataset\n",
    "## Seu código aqui....\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificar se possui dados ausentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Seu código aqui....\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aparentemente, não possui dados ausente. Vamos visualizar de forma diferente..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v2 in df:\n",
    "    print(df[v2].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça a interpretação das informações, observe o caracter `?`. \n",
    "\n",
    "Em quais colunas ele aparece?\n",
    "\n",
    "Faça o replace dos `?` por np.NaN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Seu código aqui...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ver como ficou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note que agora conseguimos ver que existem dados faltantes no dataset.\n",
    "\n",
    "Use o método `.fillna()`, para substituir os nulos (np.nan) por zero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Seu código aqui...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainda temos um problema, os classificadores que estudamos até agora não se dão bem com variáveis categóricas.\n",
    "\n",
    "Dentre as diversas formas de se fazer isso.....\n",
    "\n",
    "Vamos utilizar a técnica de OneHotEncoder com a biblioteca `category_encoders` apenas para economizar tempo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Se necessário, pip install category_encoders\n",
    "\n",
    "import category_encoders as ce\n",
    "\n",
    "encoder = ce.OneHotEncoder(cols=[\"----Coloque aqui as colunas categoricas para realizar a transformação----\"])\n",
    "\n",
    "df = encoder.fit_transform(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criamos um novo problema, os valores estão em escalas muito diferentes, o que pode prejudicar o aprendizado. \n",
    "\n",
    "Podemos tomar algumas descições:\n",
    "    Vamos normatizar os dados, mas antes, faça o drop da coluna `income` para não mudar a escala dela;\n",
    "    Da um replace na coluna `income` para 0 ou 1. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variavel independente: --> X\n",
    "Variavel dependente: --> y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos fazer um drop da coluna de interesse de estudo `income`. (y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Faça a normalização dos dados\n",
    "## escolha um dos métodos....\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "## seu código aqui...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora sim! temos uma base limpa e organizada para rodar diversos modelos de ML. onde:\n",
    "\n",
    "X - > possui as variaveis independentes.\n",
    "y - > é a nossa variavel de interesse. \n",
    "\n",
    "Separe os dados em treino e teste, qual a propoção será utiizada para cada subset??\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separar os dados em treino e teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificadores Naive Bayes\n",
    "\n",
    "Trata-se de \"classificadores probabilísticos\" simples, baseados na aplicação do `teorema de Bayes` com fortes pressupostos de independência entre os atributos. Eles estão entre os modelos de rede bayesianos mais simples. \n",
    "\n",
    "Existem 3 tipos diferentes de Naive Bayes:\n",
    "\n",
    "    1.Gaussian Naive Bayes\n",
    "\n",
    "    2.Multinomial Naive Bayes\n",
    "\n",
    "    3.Bernoulli Naive Bayes\n",
    "    \n",
    "    \n",
    "São muiiiitttooo utilizados em aplicação com texto e NLP e aplicações como:\n",
    "    \n",
    "    [X] Filtro de Spam\n",
    "    [X] Classificação de Texto\n",
    "    [X] Analise de sentimento\n",
    "    [X] Sistemas de recomendação\n",
    "\n",
    "Para mais referências: https://en.wikipedia.org/wiki/Naive_Bayes_classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred = gnb.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = gnb.predict(X_train)\n",
    "y_pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare o resultado de acuracia com pelo menos 1 outro método de machine learning. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### sua resposta aqui....\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
